id_title,context
0101,我々人間は，日々五感を通して得られる情報から，対象を分類する能力や，事象の背後にある規則性を獲得してゆきます．これらと同じ能力，あるいは人間を超える能力をコンピュータに与えることを目指したものが，機械学習です．本章では，近年機械学習が注目されている背景を紹介し，機械学習とは何かを明確にした後，本書で扱う機械学習の概要について説明します．
0102,"近年，日常生活やビジネスにおけるさまざまな場面で
人工知能 (aritificial intelligence)
を活用した製品やサービスの開発が注目されています．人工知能は，人と対話を行うアプリやロボット・自動運転・病気の診断の補助・高度な生産システムなどの中心的技術として位置づけられています．人工知能はさまざまな立場から異なった定義がされていますが，本書では人工知能を「現在，人が行っている知的な判断を代わりに行う技術」と定義します．

このように定義すると，探索・知識表現・推論などの技術とともに，データから規則性を導く
機械学習 (machine learning)
も「人が行っている知的な判断を代わりに行う」技術を実現するための，ひとつの方法ということになります（図1.1）．

この定義のもとでは，「人工知能=機械学習」ではありません．知的に振る舞うシステムを作る方法は，機械学習だけとは限りません．開発者が，その振る舞いの規則をプログラムとして作成することによっても，それなりに知的に振る舞うシステムは作製できます．日常生活で我々が便利だと感じている技術の大半は，人間が作成したプログラムで動いています．また，機械可読な web 情報源の構築を目指した LOD (linked open data) の取り組みや，システムが結論を出した過程をわかりやすく人に説明するための推論・プランニングの技術は，直接的には機械学習とは関係がなくとも，知的なシステムを作成するために重要な人工知能の要素技術です．"
0103,"機械学習の出番は，簡単には規則化できない複雑なデータが大量にあり，そこから得られる知見が有用であることが期待されるときです．このような大量のデータは，
ビッグデータ (big data)
とよばれます．
ビッグデータの例としては，人々がブログやSNS (social networking service) に投稿する文章・画像・動画，スマートフォンなどに搭載されているセンサから収集される情報，オンラインショップやコンビニエンスストアの販売記録・IC乗車券の乗降記録など，多種多様なものです．この大量・多様なデータから規則性を抽出したり，データを分類するモデルを獲得することで，購買記録からのお勧め商品提示のようなおなじみの機能に加えて，不審者の行動パターンの検出や，インフルエンザの流行の予想など，これまでになかったサービスや機能を実現することもできます（図1.2）．"
0104,"データから規則や知見を得る機械学習技術のなかでも，特に
深層学習 (deep learning)
は，高い性能を実現する方法として近年注目を集めています．
深層学習は，一般に隠れ層を多くもつニューラルネットワーク（図1.3）によって実装されています．

深層学習が他の機械学習手法と異なるのは，深い階層構造をとることによって，従来は人手でプログラムされていた特徴抽出段階の処理を，学習の対象として取り込んでいるところでです．近年の深層学習の流行を見ると，他の機械学習技術はもう不要に見えるかもしれません．しかし，深層学習がその強さを発揮しているのは，音声・画像・自然言語など空間的・時間的に局所性を持つ入力が対象で，かつ学習データが大量にある問題であるという傾向があります．さまざまな問題に対して機械学習アルゴリズムの性能を競うサイトでは，深層学習と並んで勾配ブースティングなどの手法が上位を占めることがあります．また一方で，性能は多少低くてもよいので判定結果に至るプロセスがわかりやすい手法や，運用後のチューニングが容易な手法が好まれる場合もあり，さまざまな状況でさまざまな問題に取り組むためには，深層学習だけではなく機械学習手法全般に関して理解しておくことが必要であるといえます．本書では機械学習全般に関して，設定した問題に対する基本的な手法の概要と，フリーソフトを用いた例題の解法について説明します．"
0105,"ここでは，もう少し詳細に機械学習の中身をみてゆきましょう．機械学習で扱うのは，人手では規則を記述することが難しい問題です．すなわち，解法が明確にはわかっていない問題であると言い換えることができます．ここでは，機械学習で対象とする問題を
タスク (task)
とよびます．

たとえば，人間は文字や音声の認識能力を学習によって身につけますが，どうやって認識をおこなっているかを説明することはできません．人間の認識能力を何らかの手法で
モデル (model)
化して，コンピュータでその能力を再現しようとする技術が，機械学習の一種である
パターン認識 (pattern recognition) 
です．

ここでのアイディアは，明示的にその手順は記述できないけれども，データ（この場合は入力とその答え）は大量に用意することができるので，そのデータを使って人間の知的活動（場合によってはそれを超えるもの）のモデルを作成しようというものです．これ以降，機械学習のために用いるデータを
学習データ (training data)
とよびます．

ここまでをまとめると，機械学習の基本的な定義は，

アルゴリズムとして明示的に解法が与えられないタスクに対して，そのタスクを遂行するためのモデルを，学習データから構築すること

となります．

また，学習データも一見多様に見えますが，金額やセンサーからの入力のような「
数値データ
」，あるいは商品名や性別のような「
カテゴリカルデータ
」が並んだものであるとすると，数値データの並びからなるデータ，カテゴリカルデータの並びからなるデータ，それらが混合したデータというように整理して考えることができます（図1.4）．
観測対象から問題設定に適した情報を選んでデータ化する処理は，
特徴抽出
とよばれます．

機械学習の役割をこのように位置付けると，図1.4中の「機械学習」としてまとめられた中身は，タスクの多様性によらず，目的とする規則・関数などのモデルを得るために，どのような学習データに対して，どのようなアルゴリズムを適用すればよいか，ということを決める学習問題と，その学習の結果得られたモデルを，新たに得られる入力に対して適用する実運用段階に分割して考えることができます
（図1.5）．

本書の対象は，主として図1.5の学習問題と定義された部分ですが，いかに実運用の際によい性能を出すか，すなわち，学習段階ではみたことのない入力に対して，いかによい結果を出力するかということを常に考えることになります．この能力は，「学習データからいかに一般化されたモデルが獲得されているか」ということになるので
汎化 (generalization) 
能力といいます．"
0106,
0107,
0108,
0109,"ここでは，前節で説明した学習データと出力を基準に機械学習の分類を試みます．
機械学習にはさまざまなアルゴリズムがあり，その分類に関してもさまざまな視点があります．
機械学習の入門的な文献では，モデルの種類に基づく分類が行われていることが多いのですが，そもそもそのモデルがどのようなものかというイメージをもっていない初学者には，なかなか納得しにくい分類にみえてしまいます．そこで本書では，入力である学習データの種類と出力の種類の組合せで機械学習のタスクの分類をおこない，それぞれに分類されたタスクを解決する手法としてモデルを紹介します．

まず，学習データにおいて，正解（各データに対してこういう結果を出力して欲しいという情報）が付いているか，いないかで大きく分類します（図1.6）．学習データに正解が付いている場合の学習を
教師あり学習  (supervised learning) 
，正解が付いていない場合の学習を
教師なし学習  (unsupervised learning)
とよびます．また，少し曖昧な定義ですが，それらのいずれにも当てはまらない手法を
中間的学習 
とよぶことにします．

教師あり／なしの学習については，それぞれの出力の内容に基づいてさらに分類をおこないます．教師あり学習では，入力の分類結果をカテゴリとして出力するものを識別とし，入力から予測される数値を出力するものを回帰とします．
一方，教師なし学習では観点を変えて，入力となるデータ集合全体を説明する情報を出力するものをモデル推定とし，
入力となるデータ集合の一部から得られる特徴的な情報を出力するものをパターンマイニングとします．

中間的学習に関しては，何が「中間」であるのかに着目します．学習データが中間である場合（すなわち，正解付きの学習
データと正解なしの学習データが混在している場合）である半教師あり学習という設定と，正解が間接的・確率的に与えられるという意味で，教師あり／なしの中間的な強化学習という設定を取り上げます．

以下では，それぞれの分類について，その問題設定を説明します．"
0110,"教師あり学習では，正解の付いた学習データを用います．このデータを訓練例とよぶこともあります．学習データは，入力データに対応するベクトル$\bm{x}_i$と，正解情報$y_i$のペアからなります．

ここで，$N$は学習データの総数，添字$i$は学習データ中の$i$番目の事例であることを示します．

当面，入力ベクトル$\bm{x}_i$は次元数$d$の固定長ベクトルであると考えておきます．

図1.4の上部に示したような， (134.1, 34.6, 12.9) や， (女, 68, 165, 44, no) などが入力ベクトル$\bm{x}_i$の例です．

入力ベクトルの各要素 $x_{i1},\dots,x_{id}$ を，
特徴 (feature)
 あるいは
 属性 (attribute) 
 とよびます．
特徴は，数値データあるいはカテゴリカルデータのいずれかです．数値データは長さや温度などの連続値をとる場合もあれば，商品の購入個数や単語の出現回数などの離散値をとることもあります．また，カテゴリカルデータは一般に文字列として表記され，たとえば性別を表す「男・女」や天候を表す「晴・曇・雨」などのカテゴリを値とします．

教師あり学習は，この学習データから，入力$\bm{x}$を正解$y$に写像する関数$c$を学習することを目的とします．

ここで$\bm{x}$は，学習データ中の$\bm{x}_i$に限らず，今後この関数に入力され得るすべてのデータを表しているので，関数$c(\bm{x})$はあらゆる入力に対して正しい出力を与える理想的な写像ということになります．機械学習では，そのような理想的な写像を求める問題に対して，関数の形を扱いやすいものに仮定して，その関数のパラメータを学習データから推定するという問題に置き換えます．この推定する関数を
$\hat{c}(\bm{x})$と記述します．関数$\hat{c}(\bm{x})$の実際の形は，入力ベクトル$\bm{x}$と正解$y$の種類によって異なります．

また，正解情報（あるいは関数$\hat{c}(\bm{x})$の出力）$y$も，数値あるいはカテゴリのいずれかになります．正解$y$が数値の場合を回帰 (regression) 問題，カテゴリの場合を識別 (classification) 問題とよびます．回帰問題の正解をターゲット (target) ，識別問題の正解をクラス (class) とよぶこととします．

具体的な教師あり学習問題の説明に入る前に，性能測定基準について少し説明します．学習結果である関数$\hat{c}(\bm{x})$は，学習データに含まれていない未知のデータ$\bm{x}$に対してなるべく正しい答えを出力するように一般化されなければなりません．学習データに対する正解率ではなく，未知のデータに対する正解率が重要なのです．学習データに対しては，その正解をすべて表形式で記録しておけば，間違いなく正解を出力することができます．しかし，未知データに対して正解を出力するには，「学習データの背後にある法則のようなもの」を獲得する必要があるのです．機械学習は，人間が解き方のわからない問題に対して適用するものであることを，前節で説明しました．「学習データの背後にある法則のようなもの」をいかにして獲得するか，ということが教師あり学習のテーマになります．"
0111,"識別は，入力をあらかじめ定められたクラスに分類する問題です．典型的な識別問題には，音声や文字の認識，レビュー文章のPN判定（positive（ほめている）か negative（けなしている）か），疾病の有無の判定などがあります．

ここで，識別問題としてもっとも単純な，2値分類問題を考えてみましょう．2値分類問題とは，たとえば，ある病気かそうでないか，迷惑メールかそうでないかなど，入力を2クラスに分類する問題です．さらに，入力を数値のみを要素とするベクトルと仮定します．入力ベクトルが2次元の場合，学習データは図1.7(a)に示すように，平面上の点集合になります．クラスの値に対応させて，それぞれ丸とバツで表しました．

最も単純に考えると，識別問題はこの平面上で二つのクラスを分ける境界線を決めるという問題になります．未知のデータが入力されたとき，この境界線のどちらにあるかを調べるだけで，属するクラスを解答できるので，このことによって，識別能力を身につけたとみなすことができます．

境界線として1本の直線を考えてみましょう．図1.7(b)に示すように，このデータでは切片や傾きをどのように調整しても1本の直線で二つのクラスをきれいに分離することはできません．一方，図1.7(c)のように複雑に直線を組み合わせると，すべての学習データに対して同じクラスに属するデータが境界線の片側に位置するようになり，きれいに分離できたことになります．しかしここで，「識別とは図1.7(c)のようなすべての学習データをきれいに分離する，複雑な境界線を探すことだ」という早とちりをしてはいけません．識別の目的は，学習データに対して100\%の識別率を達成することではなく，未知の入力をなるべく高い識別率で分類するような境界線を探すことでした．もう一度図1.7(a)に戻って，二つのクラスの塊をぼんやりとイメージしたとき，その塊を区切る線として図1.7(b)，(c)いずれがよいと思えるでしょうか．おそらく大半の人が(b)を支持するでしょう．これが我々人間が身につけている汎化能力で，そのようなことを学習結果に反映させるように，学習アルゴリズムを考える必要があります．

しかし，一般的な識別問題は，このような単純なものばかりではありません．識別結果が一つのクラスになるとは限らない場合があります．たとえば，受信した電子メールに対して，重要・緊急・予定・締切...などのタグを付与する自動タグ付けを識別問題に当てはめると，一つの入力に対して，複数の出力の可能性がある問題設定になります．また，どのクラスにも当てはまらない入力が入ってくる可能性もあります．たとえば，スキャンした文書に対して文字認識をおこなっているときに，文字コードにない記号が含まれている場合があるかもしれません．

本書で扱う識別は，これらの複数出力の可能性や，識別不可能な入力の問題を除外して，すべての入力に対してあらかじめ決められたクラスのうちの一つを出力とする，というように単純化します．識別の代表的な手法には決定木，ナイーブベイズ識別， ロジスティック識別，サポートベクトルマシン，ニューラルネットワークなどがあります．これらを第3章から第8章で説明します．近年注目を集めている深層学習は，主としてこの識別問題に適用されて高い性能を実現しています．深層学習に関しては第9章で説明します．また，第10章では複数の識別器を組み合わせる手法を，第13章では系列データの識別手法を扱います．"
0112,"回帰は入力から予測される妥当な出力値を求める問題です．典型的な回帰問題には，消費電力の予測，中古車の価格算出，生産量計画などがあります．
回帰の単純な例として，入力を気温，出力をビールの売上高とした架空のデータ（図1.8(a)）を考えてみます．

未知データに対して妥当な出力値を求めるために，入力データがある関数に基づいてターゲットを出力していると考え，その関数を求める問題が回帰問題です．ただし，関数の形として1次関数，2次関数，3次関数だけでなく，三角関数や指数関数などとの組み合わせまで考えてもよいとなると手がつけられなくなるので，通常は関数の形を先に決めて，その係数を学習データから推定するという問題とみなします．

1次関数を仮定して，学習データとの誤差が最も少なくなるように係数を求めると，図1.8(b)に示すような直線が得られます．ほとんどの点がこの直線を外れているので，あまりよい近似とはいえないようにみえるかもしれません．一方，複雑な高次の関数を前提とすれば，図1.8(c)に示すように，すべての学習データを通る関数を求めることができます．このどちらを採用すべきかについて，回帰問題でも識別問題と同様の立場をとります．すなわち，未知データに対する出力として，どちらが妥当かということを考えます．気温の少しの変化に対して売上が大きく変わるところがある図1.8(c)の関数は，やはり不自然な回帰に見えます．この例のように入力と出力を2次元で眺めることができれば，その妥当性をある程度直観的に議論できますが，通常の場合，入力は多次元なので，直観に頼らずに学習結果の妥当性を吟味する方法を考えなければなりません．

回帰の代表的な手法には線形回帰，回帰木，モデル木などがあります．これらを第6章で説明します．"
0113,"教師なし学習では，学習に用いられるデータに正解情報が付いていません．

入力ベクトル$\bm{x}_i$の次元数に関しては，教師あり学習の場合と同様に，$d$次元の固定長ベクトルで，各要素は数値あるいはカテゴリのいずれかの値をとると考えておきます．

教師なし学習は，入力データに潜む規則性を学習することを目的とします．ここで着目すべき規則性としては，2通り考えられます．一つめは，入力データ全体を支配する規則性で，これを学習によって推定するの問題が
モデル推定 (model estimation)
です．もう一つは，入力データの部分集合内あるいはデータの部分集合間に成り立つ規則性で，通常は多数のデータの中に埋もれてみえにくくなっているものです．これを発見する問題が
パターンマイニング (pattern mining) 
です．"
0114,"モデル推定は，入力データ中から何らかの共通点を持つデータをまとめることで，入力データを生じさせたクラスの存在や，そのパラメータを推定するものです．
図1.9にモデル推定の考え方を示します．

観測されたデータは，もともと何らかのクラスに属していたものが，揺らぎを伴って生成されたものと考えます．その逆のプロセスをたどることができれば，データを生成したもととなったと推定されるクラスを見つけることができます．発見されたクラスの性質は，そこから生成されたと推定されるデータを分析することでわかります．もしかしたら，その発見されたクラスは，誰も考えつかなかった性質をもつものかもしれません．

このように，入力データ集合から適切なまとまりを作ることでクラスを推定する手法を
クラスタリング (clustering) 
とよびます．顧客をクラスタリングした結果から特徴的な属性を見つけ出し，それぞれに適したマーケティングを行うような応用や，製品に対する口コミ文書をクラスタリングして，典型的な不満や要望を抽出する応用などが考えられています．

一方，もともとのクラスは何らかのデータを生成する関数をもっていると仮定して，その関数のパラメータを入力データから推定する手法を
密度推定  (density estimation) 
とよびます．密度推定はクラスタリングを発展させたものとみることができますが，その応用はクラスタリングだけでなく，不完全データを対象としたモデル推定の問題や，異常なデータの検出など，いろいろな場面で用いられています．

クラスタリングの代表的な手法には，階層的クラスタリングや k-means 法があり，密度推定の手法としてはEMアルゴリズムがあります．これらを第11章で説明します．"
0115,"パターンマイニングは，データ中に何度も出現するパターンや，そのパターンに基づいた規則を発見する手法です．スーパーマーケットなどで同時に購入される商品の組み合わせを発見するバスケット分析が代表的な応用例です．図1.10にパターンマイニングの考え方を示します．

パターンマイニングの敵は膨大な計算量です．まさに，大量のデータの中から，貴重な知見をマイニング（＝発掘）する作業です．図1.10に示した例では，発見された規則の条件部も結論部も要素数が一つなので，すべての商品の組み合わせに対してその出現頻度を計算することは，それほど膨大な計算量にはみえません．しかし，一般的なパターンマイニングでは，条件部・結論部のいずれも要素の集合となります．それらのあらゆる組み合わせに対して，マイニングの対象となる大きなデータ集合から出現数を数えあげなければならないので，単純な方法では気の遠くなるような計算量になってしまいます．そこで効率よく頻出パターンを見つけ出す手法が必要になります．

パターンマイニングの代表的な手法としては Apriori アルゴリズムやその高速化版である FP-Growth があります．これらを第12章で説明します．"
0116,"ここでは，これまでに説明した教師あり学習／教師なし学習に当てはまらない問題について説明します．
学習データが教師あり／教師なしの混在となっているものが半教師あり学習です．また，与えられる正解が間接的で，教師あり／教師なしの中間的な状況となっているものが強化学習です．"
0117,"これまでに述べてきた機械学習の分類では，学習データすべてに対して正解が与えられているか，あるいはまったく与えられていないかのいずれかでした．その中間的な設定として，学習データの一部にだけ正解が与えられている場合が考えられます．

学習データに正解を与えるのは人間なので，正解付きのデータを作成するにはコスト（費用・時間）がかかります．一方，正解なしのデータならば，容易にかつ大量に入手可能であるという状況があります．たとえば，ある製品の評価をしているブログエントリーのPN判定をおこなう問題では，正解付きデータを1,000件作成するのはなかなか大変ですが，ブログエントリーそのものは，webクローラプログラムを使えば，自動的に何万件でも集まります．このような状況で，正解付きデータから得られた識別器の性能を，正解なしデータを使って向上させる問題を半教師あり学習 (semi-supervised learning) といいます．半教師あり学習は主として識別問題に対して用いられます．半教師あり学習の代表的な手法のアイディアを図1.11に示します．

図1.11左のように，全データの中で正解の付加されたデータを丸・バツで表し，正解のないデータを三角形で表します．最初は丸・バツが付いたデータだけから識別器を作り，たとえば，その中間あたりに境界直線を引いたものとします．これに従って三角形のデータを分類しますが，境界線近辺のデータはあまり信用せず，境界線から大きく離れたものを確信度が高いとみなして正解を付与します．今度は，これらの新しく正解を付与されたデータも加えて，再度識別境界を計算します．これを，新しい正解付きデータが増えなくなるまで繰り返します．

この学習法は，識別するべきクラスがうまくまとまっているようなデータや，識別結果によって有効な特徴が増えてゆくような，やや特殊なデータに対して適用するときにうまくゆきます．この手法を第14章で説明します．"
0118,"問題の性質によっては，間接的に正解が与えられる場合があります．図1.12のような迷路を抜けるロボットを学習させる場合を考えてみましょう．この場合，入力はロボットの持つセンサーからの情報で，これによって，ロボットはどの部屋にいるかがわかるものとします．出力はロボットの移動コマンド（この場合，上下左右いずれかへ進む）であるとします．もし，すべての部屋（すなわちすべての状態）において正解（各状態での最適な移動コマンド）が与えられれば，ロボットはスタートから回り道することなくゴールにたどり着けます．

このようなロボットに対して，ゴールに着いたときだけ報酬を与えるという方法で，ロボットに試行錯誤を繰り返させながら，最終的に各状態における最適な出力（この場合は移動コマンド）を獲得させる学習手法を強化学習 (reinforcement learning) とよびます．報酬を教師信号とみなすと，これは教師時々あり学習ということができます．すなわち，教師あり／なしの中間的な設定とみなすことができ，個々の決定に正解は与えられず，決定の連続に対して，後で形を変えた間接的な教師信号が与えられる，という難しい設定になります．強化学習に関しては第15章で説明します．"
0119,この章では，近年注目されてきている人工知能・機械学習・深層学習の関係を説明し，その中心的な技術である機械学習について概要を示しました．また，教師あり／なしという基準から機械学習における様々な問題を分類し，それぞれの目的を説明しました．
0201,本章では，機械学習の基本的な手順を学びましょう．まず，それぞれのステップで理解しておくべき内容を解説した後で，各ステップの作業を支援してくれるツールやコマンドを使いながら，具体的なデータでその内容を説明します．学習の中身に関しては次章以降で学ぶので，この章では少し特殊な学習法である「学習しない」機械学習手法（k-NN法）を使って，機械学習全体の手順（図2.1）を説明します．この章ではまず，WekaのExplorerインタフェースを用いて機械学習全体の流れをGUI (graphical user interface)を用いて実行する手順を説明します．その後，Pythonの機械学習ライブラリ scikit-learnで，同様の手順を実行する方法を説明します．次章以降の例題・演習問題では，これら2つの環境を必要に応じて使い分けて用います．
0202,Wekaは，機械学習を含むデータマイニング一般のアルゴリズムを実装したJavaのライブラリとして開発されました．用途に応じたGUIも複数備えています．本節では，そのGUIの一つであるExplorerインタフェースを用いて，図2.1に示した機械学習の手順を構成してみます．
0203,"機械学習の第一段階はデータ収集です．購買記録からのパターンマイニングなどのように使用するデータがあらかじめ存在する場合と，自分でタスクと問題を設定して，そのために必要なデータを集める場合とがあります．教師あり学習を行う場合には，さらに正解の付与作業が必要になります．

第1章で説明したように，機械学習に用いる学習データは多次元ベクトルの集合です．この場合，ベクトルの各要素をカンマで区切り，1行に1事例ずつデータを並べてゆくというのが，最も単純な形式になります．この形式は CSV (comma separated values) 形式とよばれ，表計算ソフトやテキストエディタで表示・編集・保存ができます．ただしCSV形式では，カンマで区切られた何番目の要素が，どのような特徴を表しているのかはデータだけからはわかりません．最初に見出し行を付けるという方法も考えられますが，データの型など，もう少し情報をつけておきたいこともあります．それぞれの要素は数値なのかカテゴリなのか，カテゴリの場合はどのような値が可能なのかという情報も，自分が作成したものではないデータを扱う際には役に立ちます．CSV形式にこれらの情報をヘッダ情報として加えたものがWekaの標準データフォーマットである
ARFF (attribute-relation file format) 
形式です．

ARFF形式のデータの例として，Wekaに付属の iris.arff を図2.2に示します．これはアヤメ (iris) の種類を，その萼（がく）の長さ (sepal length) ・幅 (sepal width) ，花びらの長さ (petal length) ・幅 (petal width) の，計四つの特徴を用いて識別するための学習データです．各事例の最後には，正解情報（Iris-setosa, Iris-versicolor, Iris-virginicaのいずれか）が付いています． 
ARFF形式のファイルにはデータセット名，特徴の情報，学習データを，この順で記述します．それぞれの記述方法について表2.1にまとめます．
{\tt \%}で始まる行はコメントです．Weka付属のデータのいくつかには，コメントとしてそのデータの作成元の情報，関係論文，特徴の詳細説明などが書かれています．

{\tt @relation}で指定するデータセット名は，ほかのデータ集合と区別する目的で，英数字または記号を用いて記述します．

{\tt @attribute}では，特徴名とその型を指定します．特徴の型は，{\tt numeric}（数値），カテゴリ，{\tt date}（日付），{\tt string}（文字列）のいずれかです，数値型として，{\tt integer} や {\tt real} と書かれているデータもありますが，いずれも {\tt numeric} と見なされます．カテゴリ型の場合は，カテゴリとして可能な値を {\tt \{yes, no\}} のようにカンマ区切りで並べて波括弧で囲みます．識別問題の正解情報は，このカテゴリ型を用いて，特徴名として {\tt class} と指定することが一般的です．

{\tt @data} と書いた次の行から，学習に用いるデータを1行に1事例のCSV形式で記述します．"
0204,"ここでは，次元削減と標準化を紹介します．

次元削減
とは，特徴ベクトルの次元数を減らすことです．せっかく用意した特徴を減らすと聞くと，不思議な感じがするかもしれません．しかし一般的には，多次元の特徴には冗長性が多く含まれます．また，次元数が増えれば増えるほど，学習データが高次元空間上にまばらに存在することになり，そのようなまばらなデータから得られたモデルは，一般的に汎化能力が低いことがわかっています．これを「
次元の呪い
」とよびます．したがって，特徴ベクトルの次元削減は，より汎化能力の高いモデルを学習するという観点から，重要な前処理ということになります．
また，特徴の値の範囲を揃えておく
標準化 (standardization)
も，前処理としては重要な処理です．一般に，特徴はそれぞれ独立の基準で計測・算出するので，その絶対値や分散が大きく異なります．これをベクトルとして組み合わせて，そのまま学習をおこなうと，絶対値の大きい特徴量の寄与が大きくなりすぎるという問題があるので，値のスケールを合わせる必要があります．また，入力の平均値を特定の値に合わせておくと，学習対象のパラメータの初期値を個別のデータに合わせて調整する必要がなくなります．このようなことを目的として，一般的には式(2.4)に従ってそれぞれの次元の平均値を0に，標準偏差を1に揃えます．この処理を標準化とよびます．"
0205,"ここでは，特徴数削減の手法として，
主成分分析 (principal component analysis: PCA) 
を紹介します．図2.5に，2次元から1次元への削減を例として，主成分分析の考え方を示します．
主成分分析とは，相関が高い特徴を複数含むような冗長な高次元空間を，冗長性の少ない低次元空間に写像する行列を求める操作です．次元削減の対象である高次元特徴空間上にデータがどのように散らばっているかという情報は，もとのデータの統計的性質をあらわす共分散行列によって表現することができるので，この共分散行列の情報を基にして，低次元空間への写像をおこなう行列を作ってゆきます．

学習データ$\{\bm{x} | \bm{x} \in D\}$の共分散行列$\Sigma$は式(2.1)を用いて計算されます．
ここで，$\bm{\mu}$は$D$の平均ベクトル，$N$は$D$の要素数です．平均ベクトル$\bm{\mu}$は式(2.2)を用いて計算されます．
図2.5左上に示すような2次元データの場合，平均ベクトルを$\bm{\mu}=(\bar{x_1}, \bar{x_2})^T$とすると，
共分散行列$\Sigma$は式(2.3)のようになります．
対角成分は，次元ごとの散らばり具合を表す分散に対応し，非対角成分は次元間の相関を表します．

次に，この共分散行列の固有値と固有ベクトルを求めると，固有値の大きい順にその対応する固有ベクトルの方向が，データの散らばりが大きい（すなわち，識別するにあたって情報が多い）方向となります．固有ベクトルどうしは直交するので，固有値の大きい順に軸として採用し，特徴空間を構成すると，たとえば上位$n$位までなら$n$次元空間が構成でき，これらはもとの多次元特徴空間のデータの散らばりを最もよく保存した$n$次元空間ということになります．特徴空間の次元数が下がれば下がるほど，学習において推定するべきパラメータ数が少なくなるので，学習結果の信頼性が高まります．もっとも，もとのデータの情報が大きく損なわれるほどに次元を削減してしまっては意味がないので，そのあたりの調整は難しいところです．主成分分析によって構成した軸では，対応する固有値が分散になるので，「すべての軸の固有値の和」に対する「採用した軸の固有値の和」の比（累積寄与率）を計算することで，次元削減後の空間が，もとのデータの情報をどの程度保存しているのか，見当をつけることができます．"
0206,"それでは学習です，とゆきたいところですが，その前に学習結果の評価基準を設定します．

ここで扱っているデータはirisデータなので，教師あり・識別の場合の評価基準を考えます．この場合，学習データに対して正解率100\%でも意味がありません．未知データに対してどれだけの正解率が期待できるかが評価のポイントですが，どうやって未知データで評価すればよいのでしょうか．

学習データが大量にある場合は，半分を学習用，残り半分を評価用として分ける方法が考えられます．この方法を
分割学習法
とよびます．
評価用に半分というのは，多すぎるように見えるかもしれませんが，評価用データがあまりに少ないと，未知データの分布と全く異なる可能性が高くなり，評価そのものが信頼できなくなります．また，学習パラメータの調整をおこなうような場合では，データを学習用・調整用・評価用と分けるケースもあります．

しかし，irisデータは150事例しかないので，分割学習法で評価するのは難しそうです．このような場合，一般的には
交差確認法(cross validation method: CV法)
とよばれる方法を用いて評価します(図2.7)．この方法では学習データを$m$個の集合に分割し，そのうちの$m-1$個で学習を行い，除外した残りの一つで評価を行います．そして，その除外するデータを順に交換することで，合計$m$回の学習と評価を行います．これで，全データがひととおり評価に使われ，かつその評価時に用いられる識別器は評価用データを除いて構築されたものとなっています．$m$を交差数とよび，技術論文では交差数$m$を10とするケース (10-fold CV) や，データの個数とするケースがよく見られます．$m$がデータの個数の場合を
一つ抜き法(leave-one-out method)
とよびます．"
0207,
0208,"さて，いよいよ学習です．ここでは学習アルゴリズムとして，入力されたデータに近い学習データを近い順に$k$個選び，多数決などで所属するクラスを決定する
k-NN法 (k-nearest neighbor method) 
を使います（図2.9）．
k-NN法は，いわば学習データを集めるだけの学習法です．$k=1$の場合，識別したいデータと最も近い学習データを探して，その学習データが属するクラスを答えとします．$k>1$の場合は，多数決を取るか，距離の重み付き投票で識別結果を決めます．このk-NN法で調整するべきパラメータは，近傍としていくつまでの学習データを考えるか（すなわち$k$の値）になります．また，学習データが多い場合，効率よく近傍を探索するアルゴリズムを組み合わせることもあります．

これから機械学習を学ぼうと意気込んでいるみなさんに，最初に紹介するのが「学習しない」学習法なので，がっかりされたかもしれません．しかし，データが大量に入手・記録可能で，かつ並列で高速に近傍計算ができる現在では，k-NN法は驚くほどの性能を示すこともあります．たとえば，スマートフォンの音声対話アプリで実現されている発話理解手法の一部は，k-NN法の考え方に近いものです．"
0209,"最後のステップは，学習結果の可視化です．識別結果からいくつかの評価指標の値を計算し，表やグラフとして表示します．
まず，説明を単純にするために2クラス識別問題の評価法を考えます．
2クラス問題では，入力がある概念に当てはまるか否かを判定します．たとえば，ある病気か否か，迷惑メールか否か，というような問題です．設定した概念に当てはまる学習データを正例 (positve) ，当てはまらないデータを負例 (negative) といいます．
迷惑メールの識別問題では，迷惑メールが正例なので，これをpositiveと見なすのは少し変な気がしますが，惑わされないでください．あくまでも設定した概念に当てはまるか否かで，正例・負例が決まります．

さて，識別器を作成し，テストデータでその評価を行うと，その結果は表2.3で表すことができます．正例を正解+，負例を正解-，識別器が正と判定したものを予測+，負と判定したものを予測-とします．この表のことを
混同行列(confusion matrix)
あるいは
分割表(contingency table)
とよびます．
実は，機械学習の評価は，正解率を算出して終わり，というほど単純なものではありません．たとえば，正例に比べて負例が大量にあるデータを考えてみましょう．もし，正例のデータがでたらめに判定されていても，負例のデータがほとんど正確に判定されていたとしたら，正解率は相当高いものになります．そのような状況を見極めるために，機械学習の結果は様々な指標で評価する必要があります．有効な指標を紹介する前に，まず，混同行列の各要素に表2.4に示す名前をつけておきます．

たとえば，左上の要素は，正例に対して識別器が正 (positive) であると正しく (true) 判定したので，true positive といいます．一方，右上の要素は，正例に対して識別器が負 (negative) であると間違って (false) 判定したので，false negativeとよびます．前の語が判定の成否 (true or false) を，後の語が判定結果 (positive or negative) を表します．

これらの定義を用いると，正解率 Accuracy は式(2.5)のように定義できます．

また，識別器が正例と判断したときに，それがどれだけ信頼できるかという指標を表すために，
精度(precision)
が式(2.6)のように定義されます．

さらに，正例がどれだけ正しく判定されているか
という指標を表すために，
再現率(recall)
が式(2.7)のように定義されます．
精度と再現率を総合的に判断するために，その調和平均

をとったものをF値(F-measure)とよび，式(2.8)のように定義されます．"
0210,"精度と再現率は一般にトレードオフの関係にあり，識別器によっては，パラメータ設定でその値を調整することができます．
たとえば，irisデータのsepallength特徴だけを用いて閾値$\theta$を設定し，入力が$\theta$以下であればIris-setosa(正例)と判定する
単純な識別器を考えてみます．sepallength特徴の値の分布は図2.10のようになり，どこに閾値$\theta$を設定しても精度・再現率ともに1となることはありません．$\theta$を小さめ(たとえば4.8)に設定すれば，精度は1ですが，再現率が悪くなります．一方，$\theta$を大きめ(例えば6.0)に設定すれば再現率は1になりますが，精度が下がります．

タスクによっては，精度を重視してパラメータを設定することもあれば，逆に再現率を重視する場合もあるでしょう．特にどちらかを重視という状況でなければ，F値で性能を測定するのが妥当です．"
0211,"精度あるいは再現率のどちらかを重視する場合に，閾値を変えたときの精度と再現率の関係を見ることができれば，タスクで要求される適切な設定にすることができます．このためには，
ROC曲線(ROC curve)
（図2.11）を用います．
ROC曲線は，横軸に false positive rate (FPR = FP/負例数), 縦軸に true positive rate (TPR = TP/正例数)をとって，閾値を変えていったときの値をプロットしたものです．
ROC曲線は必ず原点から始まり，必ず(1,1)の点で終わります．図2.11の例では，識別器のパラメータを$\theta < 4.3$で正例と
判定するように設定すれば，すべてのテストデータが負と判定され，TPR=FPR=0となるので，この識別器はROC曲線の原点に対応します．
一方，識別器のパラメータを$\theta < 8.0$で正例と判定するように設定すれば，すべてのテストデータが正と判定され，TPR=FPR=1となるので，この識別器はROC曲線の(1,1)の点に対応します．このパラメータを4.3から8.0まで小刻みに変化させてゆくと，原点から始まり，(1,1)で終わる図2.12のようなROC曲線を描くことができます．
このように，機械学習の結果は様々な評価指標やグラフを使って評価することになります．

ここまで説明してきた2クラスの評価手法を多クラスに適用する場合は，クラス毎の精度や再現率を求め，そのクラスのデータ数に応じた割合を掛けることで，総合的な評価を行います．"
0212,プログラミング言語Pythonはオブジェクト指向スクリプト言語です．コンパイルが不要なので，短いコードを書いてその実行結果を確認しながらプログラムを組んでゆくことができます．
0213,"本節では，scikit-learnパッケージを使って機械学習の手順をコーディングします．典型的な手順を図2.13に示し，それぞれについて以下の節で説明します．

% figure 2.13

scikit-learnでは，全体のパッケージであるsklearnのサブパッケージとして，データの読み込みから学習を行った結果表示までを行うための機能が提供されているので，これらのサブパッケージから必要なメソッドやクラスをコードの冒頭でimportしておきます．また，scikit-learnでは処理の高速化のためにnumpyを使用しているので，ほとんどすべてのコードでnumpyのimportが必要になります．これ以外に，グラフの表示のためのライブラリや，データ読み込みのためのライブラリも必要に応じて読み込んでおきます．

ここでは，前節で説明したものと同様の手順で学習をおこなうため，以下のライブラリを読み込みます．


scikit-learnでもWekaと同様にいくつかのサンプルデータが用意されています．前節で取り上げたirisデータを利用する際には，以下に示すコードを書きます．このコードで変数irisは，特徴ベクトル，正解データ，特徴名，データの説明などのさまざまな情報が詰まったオブジェクトになります．


サンプルデータのいくつかには，DESCR属性の値としてデータの概要・特徴の説明・統計情報などが記述されていますので，表示して内容を確認しています．
特徴ベクトルはdata属性の値として，また正解データはtarget属性の値として格納されているので，ここでは，以降の章での数式を用いた説明に合わせて，特徴ベクトルの集合をX，教師信号をyという変数に入れ直しておきます．

ここで，Xはnumpyのn次元アレイ(ndarray)で，データ数$\times$特徴の次元数からなる150行4列の行列です．このように特徴ベクトルを転置して，列方向に並べたものを
パターン行列
とよびます．
また，yもnumpyのn次元アレイで，150個の要素からなる列ベクトル（すなわち150行1列の行列）です．値はクラス名をあらわす文字列ではなく，それをクラス番号に置き換えた数値（irisデータは3クラスなので 0, 1, 2）が入っています．

ここではまず，主成分分析によって4次元データを2次元にする次元削減をおこない，散布図を出力して，識別問題がどのくらい難しいのかの見当をつけてみます．
主成分分析は，decompositionパッケージにあるPCAクラスのインスタンスを作成し，そのインスタンスの主成分分析をおこなうメソッドに対して変換したいデータを与えることで行います．削減後の次元数は，インスタンス作成時に n\_components 引数の値として与えます．

この結果を，matplotlibライブラリを用いてグラフで出力します．グラフの種類は，2次元平面上にデータを点でプロットする散布図を使います．
matplotlib.pyplotパッケージのplotメソッドを，第1引数としてx軸の値の並び，第2引数としてy軸の値の並び，第3引数として点の種類をあらわす記号を与えて呼び出すと，図2.14のようなグラフが表示されます．

% figure 2.14

plotメソッドの第1, 第2引数にあるX2[y==0,0]のような記述は，行列X2の中から，ベクトルyの値が0である行に対応する行だけ取り出し，その0列目を抜き出すということを示しています．また，第3引数の1文字目は色，2文字目は点の形を示しています．

ここでは，主成分分析の結果は，データのクラスごとのまとまり具合を見る程度にしておいて，識別にはもとの4次元データを使います．次に，パターン行列Xに対して，各特徴の平均と分散を揃える標準化処理を行います．scikit-learnでは，さまざまな前処理がpreprocessingサブパッケージに用意されています．標準化を行うメソッドはscaleです．

この処理で平均0，標準偏差1になっていることは，\texttt{X\_scaled.mean(axis=0)}，\texttt{X\_scaled.std(axis=0)}の結果を表示させて確認することができます．なお，それぞれのメソッドの引数\texttt{axis=0}は，列単位でそれぞれの処理を行うことを指示しています．

scikit-learnでは，さまざまな学習アルゴリズムを実現した識別器がクラスとして用意されています．scikit-learnにおける学習の基本的な手順
は以下のようになります．
\begin{enumerate}
\item 学習時のパラメータを引数として，識別器クラスのインスタンスを作成
\item 特徴ベクトルと教師ベクトルを引数として，fitメソッドを実行
\item 識別したい特徴ベクトルを引数として，predictメソッドを実行
\end{enumerate}

学習時のパラメータの種類やその値は，実装されているアルゴリズムによって異なりますが，一度インスタンスを作成すると，
fitメソッドで学習，predictメソッドで予測という手順は共通になります．

特定の学習アルゴリズムを交差確認法で評価するには，識別器のインスタンスを作成し，交差確認をおこなうメソッドに学習データとともに渡すという手順になります．まず，パラメータを与えて識別器のインスタンスを作成します．k-NN法は，neighborsパッケージにKNeighborsClassifierクラスとして実装されています．
ここでは，探索する近傍のデータ数は1として，インスタンスを作成します．

識別器のインスタンスの値の表示には，パラメータの値も含まれます．インスタンス作成時に指定していないパラメータがいくつも現れていますが，これはPythonでの関数呼び出しにおけるデフォルト引数の機能を使ったものです．明示的に指定していないパラメータは，デフォルトの値が適用されます．パラメータの種類やデフォルトの値は，API Referenceを読んで確認しておくようにしましょう．

学習と評価は，model\_selectionパッケージのcross\_val\_scoreメソッドを，識別器のインスタンス・学習データ・教師データ・交差数などを引数として呼び出します．戻り値のscoreは，交差数を要素数とするベクトルで，各要素は正解率を表します．

単純な正解率は，ベクトルscoreの平均で求まります．また，各交差の安定性を見るために標準偏差も合わせて表示しておきます．

結果は，95.33 +/- 6.70 \% のように表示されます．

また，混合行列を求める場合は，cross\_val\_scoreメソッドではなく，cross\_val\_predictメソッドを用いて識別器の出力を記録しておいて，
metricsパッケージのconfusion\_matrixを用いて計算します．


精度・再現率・F値はこれらの値から計算することができます．"
0301,この章では，各次元がカテゴリカルデータである特徴ベクトルと，その正解クラスの情報からなる学習データを用いて，「クラスの概念を得る方法」について説明します．例えば，「乳癌が再発しやすい」という概念を，年齢・腫瘍のサイズ・放射線治療の有無などの情報を組合せて表現することを学習することが目的になります．
0302,"第3章から第5章では，正解情報の付いた学習データを用いる教師あり学習の設定で，識別をおこなうモデルを学習する方法について説明します．
まず第3章と第4章は，カテゴリカルデータからなる特徴ベクトルを入力として，それをクラス分けする（すなわち属するクラスラベルを出力する）識別器を作る方法について学びます（図3.1）．

識別問題は教師あり学習なので，学習データは特徴ベクトル$\bm{x}_i$と正解情報$y_i$のペアからなります．

ここでの設定は，特徴ベクトル$\bm{x}_i$の各次元および正解情報$y_i$がいずれもカテゴリです．特にカテゴリ形式の正解情報のことを
クラス
とよびます．

このカテゴリ特徴に対する「教師あり・識別」問題に対して，いかに納得のゆく概念モデルを獲得するか，という点に重点を置いたものが，この章で説明する概念学習です．一方，特徴が与えられたときに，それがあるクラスに属する確率を計算するモデルの獲得を目的とするものが，第4章で説明する統計的手法です．"
0303,"
具体的に学習データを見ながら考えてゆきましょう．表3.1に示すデータは，Weka 付属の contact-lenses データで，「ソフトコンタクトレンズの使用を勧める」・「ハードコンタクトレンズの使用を勧める」・「コンタクトレンズの使用を勧めない」という概念を獲得するための架空のデータです．

それぞれの特徴は，表3.2に示すいずれかの値をとります．

このデータから，「コンタクトレンズの使用を勧めない」という概念を獲得する手順を考えてみます．対象とする概念に当てはまるデータ（クラスnoneのデータ）が正例，当てはまらないデータ（クラスsoftとクラスhardのデータ）が負例となります．"
0304,"機械学習において与えられるデータは，個々の事例です．その個々の事例から，あるクラスについて共通点を見つけることが，
概念学習
です．共通点は，特徴の値の組み合わせによって表現されます．"
0305,"概念学習手法が研究されていた初期の頃には，概念の表現形式を限定することで，データに当てはまる概念の仮説を少なくし，その仮説の空間を探索することで概念を求める手法が開発されました．そのような手法として，FIND-Sアルゴリズムや，候補削除アルゴリズムがあります（図3.2）．

FIND-Sアルゴリズムは，仮説の表現を，特徴に対する制約を論理積(AND)で結合したものに制限します．このように，仮説に対して課す制約を
バイアス
とよびます．最初は，最も特殊な仮説（いかなる事例も正ではない）からスタートし，正例を一つずつ読み込んで，その事例の値を受け入れるように仮説を最低限一般化します．

たとえば，表3.1のデータにおいて，最初の正例である1番のデータから，論理式「age=young $\wedge$ spectacle-prescrip=myope $\wedge$ astigmatism=no $\wedge$  tear-prod = reduced」が得られます．次の正例である3番のデータは，age, spectacle-prescrip, tear-prodの値はこの論理式に当てはまりますが，astigmatismの値が異なります．
1番と3番のデータの両方が当てはまるようにするために，この論理式から，astigmatismの条件を取り除き，新たな仮説を「age=young $\wedge$ spectacle-prescrip=myope $\wedge$ tear-prod = reduced」とします．

これを続けると，5番のデータでspectacle-prescripの条件が落ち，9番のデータでageの条件が落ち，最後は16番のデータでtear-prodの条件まで落ちて，条件が何もなくなってしまいます．これでは，すべての入力が正例であるという概念になり，明らかにおかしな結果になってしまいました．"
0306,"候補削除アルゴリズムは，FIND-Sアルゴリズムに加えて，負例に対して最も一般的な仮説（いかなる事例も正）を最低限特殊化するという処理を加えて，仮説の空間を特殊な論理式と一般的な論理式で挟むことによって，候補を絞り込む方法です．しかし，候補削除アルゴリズムでも表現できる仮説の制約は同じなので，FIND-Sアルゴリズムと同じ手順で，概念の学習に失敗します．

これらのアルゴリズムが，概念の学習に失敗する理由は，仮説に対するバイアスが強すぎて求めるべき概念が仮説の空間の中に存在しないことです．"
0307,"それでは，特徴値のOR結合を仮説とした機械学習は不可能なのでしょうか．もちろんそんなことはありません．仮説空間にバイアスをかけられないのなら，探索手法にバイアスをかけます．「このような探索手法で見つかった概念ならば，汎化性能が高いに決まっている」というバイアスです．ここではそのような学習手法の代表である決定木について説明します．

決定木とは，データを分類する質問をノード（節）とし，分類結果をリーフ（葉）とする木構造の概念表現です．
正例のリーフに到るノードの分岐の値をAND条件で結合し，それらをさらにOR条件で結合することで等価な論理式に変換できますが，
木構造のままの方が，人間の目から見て学習結果がわかりやすいので，こちらの表現が好まれます．

コンタクトレンズデータ (contact-lens.arff)（表3.1）から作成した決定木の例を図3.3に示します．
図3.3の木では特徴tear-prod-rate（涙量）が最初の質問で，この値がreduced（減少）であると，コンタクトレンズは勧められない，という結論になります．この値がnormal（正常）であれば，次の特徴astigmatism（乱視）を調べる，という手順になります．"
0308,"決定木の説明には，「二十の扉」という遊びがよく用いられます．「二十の扉」は，出題者が思い浮かべた概念（例えば「犬」）を，回答者が二十個以内の質問（例えば「それは生き物ですか」）を重ねて当てるクイズ遊びです．このとき，うまく対象を絞れる質問をなるべく初期に持ってくる方が，答えにたどり着く確率が高くなります．最初の質問があまりにも特殊（例えば「それは毒キノコの一種ですか」）だと，当たれば一気に候補が絞り込めますが，大抵の場合，はずれてほとんど何の情報を得たことにもなりません．

この「二十の扉」の必勝法のように，得られる情報が多い質問（ここでは特徴）をなるべく木の上のノードに持ってくるように構成されたものが決定木です．"
0309,このような決定木を作成するもっとも基本的な手順がID3アルゴリズム（アルゴリズム3.1）です．
0310,
0311,"ID3アルゴリズムの中で，詳しい説明のない「特徴集合A中で最も分類能力の高い特徴」を決定する方法について説明します．
分類能力が高いとは，「その特徴を使った分類を行うことによって，なるべくきれいに正例と負例に分かれる」という
ことです．いいかえると，乱雑さが少なくなるように分類を行うということですね．乱雑さの尺度として，エントロピーを
用います．学習データ集合$D$の乱雑さを計算するために，まず正例の割合: $P_+$,  負例の割合: $P_-$を計算し，それを元に
式(3.1)によって，その集合の乱雑さ（エントロピー）$E(D)$を求めます．

エントロピーの値は$P_+=1$または$P_-=1$のとき最小値0となり，$P_+=P_-=0.5$のとき，最大値1となるので，
エントロピーの値が小さいほど，集合が乱雑でない，すなわち整っている（同じクラスのものが大半を占めている）という
ことになります．

このエントロピーの減り具合を計算したいのですが，単純に引き算はできません．
エントロピーは集合に対して定義できるものです．分類前は1つの集合で，分類後はその特徴値の種類数だけ集合ができます．
そこで，分類後の集合の要素数の割合で重みを付けて計算します．この値を情報獲得量と定義します．"
0312,情報獲得量は，ある特徴を用いた分類後のエントロピーの減少量とします．特徴$a$の可能な値$Values(a)$の中から，値$v \in Values(a)$を取る学習データの集合を$D_v$，集合$D_v$の要素数を$|D_v|$と表現したとき，情報獲得量は式(3.2)のように定義できます．
0313,"ここで，ID3アルゴリズムにおける過学習について考えてみます．過学習とは，文字通りの意味は学習しすぎるということですが，機械学習においては，モデルが学習データに特化しすぎたために，未知データに対して性能が下がる現象を指します．

ID3アルゴリズムのバイアスは単純に表現すると，「小さい木を好む」となります．なぜ小さな木を結果とするのでしょうか．これはオッカムの剃刀 (Occam's razor) と呼ばれる「データに適合する最も単純な仮説を選べ」という基準に基づいています．長い仮説なら表現能力が高いので，偶然に学習データを説明できるかもしれないのですが，短い仮説だと，表現能力が低いので，偶然データを説明できる確率は低くなります．もし，ID3アルゴリズムによって，小さな木で学習データが説明できたとすると，これは偶然である確率は相当低くなります．すなわち偶然でなければ必然である，というわけです．

ところが，このバイアスを持って学習を行ったとしても，最後の1例までエラーがなくなるように決定木を作成してしまうと，その決定木は成長しすぎて，学習データに適応しすぎた過学習になりがちです．そこで，過学習への対処として，
適当なところで決定木の成長を止める方法（葉の要素数を一定値以下にならないようにする）や，完全に学習させた後，枝刈りするという方法があります．"
0314,"リーフの要素数は，学習データの量や性質によって左右され，事前に決めるのが難しいので，枝刈りの方が実用上有効です．
枝刈りは，学習データを学習用データと検証用データに分割し，学習用データで十分に木を成長させた（すなわち
過学習させた）のち，検証用データを用いて余分な枝を見つけて刈り取ることによって行います．決定木の枝刈りの
手順をアルゴリズム3.2に示します．ただし，$\mbox{accuracy}(T, D)$は決定木$T$を用いてデータ$D$を識別したときの正解率，
$\mbox{majority}(D)$はデータ$D$中の最頻正解ラベルの割合，$\mbox{majority\_class}(D)$はその最頻正解ラベルを求める処理を示します．"
0315,"ID3アルゴリズムで用いた情報獲得量は，値の種類が多い特徴ほど大きな値になる傾向があります．一般に，その性質は悪いもの
ではないのですが，値の種類が極端に多い場合には問題があります．
例えば表3.3の特徴として，日付(date)があったとし，その値が全てのデータで異なっているとします．

この場合，dateによって分割した集合は要素数が1となって，そのエントロピーは0となりますので，$\mbox{Gain}(D, date)$の値は
最大値である$E(D)$になって，この特徴が決定木のルートに選ばれることになります．こうして出来た決定木ではテスト例
は分類できません．

そこで，分割の程度を式(3.3)によって評価し，分割が少ない方が有利になるように式(3.4)で定義された獲得率を用いて特徴を選択することもあります．

また，学習データの性質や学習の目的によって，データの乱雑さを評価する基準も変化することがあります．
データの乱雑さを不純度(impurity)と定義すると，先述のエントロピー以外にいくつかの可能性を考える
ことができます．

式(3.5)で計算されるGini Inpurityは，分割後のデータの分散を表します．この性質は回帰木の作成
で用いますので，そこで再度，解説します．

また，Gini Inpurityの平方根を取って，最大値がGini Inpurityと同じ0.5になるように係数を補正したものを
RootGiniImpurityとして，式(3.6)で定義します．

いずれも，分割前後の値の差によって選ぶ特徴を決めるのですが，獲得率やジニ不純度
は，正例・負例の数に偏りがあると，多数派の性能の影響が大きくなってしまいます．
一方，RootGiniImpurityは，分割前のGini Inpurityと，分割後の重み付きGini Inpurityの比を計算していることになり，
正例・負例の数に偏りがあっても，分割基準としては影響を受けないようになります．"
0316,"ここでは，特徴ベクトルのなかで数値を値とする特徴がある場合の決定木学習について説明します．

基本的なアイディアとして，連続値である数値特徴を，いくつかのグループに分ける離散化という処理をおこなうことで，決定木での学習を可能にします．
具体的には，数値特徴$a_i$に対して$a_i < \theta$という条件式を値とするノードを作成します．
この条件式を満たすデータと満たさないデータに分割することで，ラベルを値として持つ特徴に対する決定木学習と同じアルゴリズムが
使えます．
問題は，閾値$\theta$をどうやって決めるかということです．

具体的にデータを見ながら，考えてゆきましょう．Weka付属のweather.numericデータ（表3.5）は，
weather.nominalデータの特徴temperatureと特徴humidityを数値にした
ものです．たとえば，特徴humidityの値でデータを分割する場合を考えてみましょう．

最もエントロピーが低くなるような切り方を見つけたいので，同じクラスの中で切ることは意味がありません．クラスの境目を探すと，図3.6に点線で示す箇所になります．この境目の値はその前後の値の平均値をしておきましょう．

これらの中で最も情報獲得量の多い場所を選びます．カテゴリ特徴のときと同様の計算を行うと，$c=82.5$となるときに（すなわち，82.5未満の値はyes，82.5以上はnoとなるカテゴリ特徴に変換したときに）最も情報獲得量が多い分割になります．

この操作をすべての数値特徴についておこなった後は，通常のID3アルゴリズムと同じです．"
0401,この章では前章に引き続き，教師あり学習における識別問題で，特徴ベクトルの要素がすべてカテゴリの場合を扱います．前章と異なるのは，識別に統計的手法を用いることによって，結果に確信度を付与することができる点です．
0402,"第3章の決定木は，ある事例がある概念に，当てはまるか否かだけを答えるものでした．しかし，たとえば病気の診断のように，その答えがどれだけ確からしいか，ということを知りたい場合も多くあります．学習データの統計的性質に基づいて，ある入力があるクラスに分類される確率を求め，最も確率が高いクラスを出力とする方法が，統計的識別手法です．

本節と次節では，第3章でも取り上げたweather.nominalデータを例に，統計的識別の考え方を説明します．

次に，入力$\bm{x}$が観測されたとします．この観測によって，事前確率からのみ判断した結果とは異なる結果が導き出される場合があります．たとえば，$\bm{x}$が悪天候を示唆しているならば，ゴルフをする確率は下がると考えられます．入力$\bm{x}$が観測されたときに，結果がクラス$\omega_i$である確率を，条件付き確率 $P(\omega_i \vert \bm{x})$ で表現します．
この確率は，入力を観測した後で計算される確率なので，
事後確率 (posterior probability) 
とよびます．

統計的識別手法の代表的な方法は，この事後確率が最大となるクラスを識別結果とする方法で，この決定規則を
最大事後確率則(maximum a posteriori probability rule)
とよびます．
式(4.1)は，事後確率最大のクラス$C_{\mbox{\scriptsize{MAP}}}$を求める式です．

% equation 4.1

それでは，この事後確率の値を学習データから求める方法を考えてゆきましょう．一般的な条件付き確率の値は，条件部（縦棒の右側）が一致するデータをできるだけ多く集め，結論部（縦棒の左側）の頻度を求めることによって推定できます．weather.nominalデータの場合では，たとえば (sunny, hot, high, FALSE) という特徴をとるデータを大量に集めてきて，その中でyesが何回，noが何回出現したという頻度を得て，その頻度から条件付き確率値を推定します．そして，この推定をあらゆる特徴値の組合せについておこないます．しかし，weather.nominalデータをみると，特徴値の組み合わせのうちのいくつかが1回ずつ出てきているだけで，可能な特徴値の組み合わせの大半は表の中に出てきません．これでは条件付き確率の推定はできません．

そこで，この事後確率の値を直接求めるのではなく，式(4.2)に示すベイズの定理
を使って，より求めやすい確率値から計算します．

% equation 4.2

式(4.1)にベイズの定理を適用すると，式(4.3)が得られます．

% align 4.3

ここで，式(4.3)の右辺の分母は，クラス番号$i$を変化させても一定なので，右辺全体が最大となるクラス番号$i$を求める際には，その値を考慮する必要がありません．したがって，事後確率を最大とするクラス番号$i$を求める式は，式(4.4)のようになります．"
0403,
0404,"突然ですが，現在の気象に関する情報が何も知らされていない状況で，weather.nominalデータだけが与えられて，今日この人がゴルフをするかどうかと尋ねられたらどう答えますか．weather.nominalデータを眺めると，全14事例のうちyesが9事例，noが5事例です．したがって，yesと答えた方が正解する確率が高そうです．この場合はあまり確信を持ってyesと答えられるとはいえませんが，プロゴルファーのような人の1年分のデータが与えられて，yesが360事例，noが5事例だったら，躊躇なくyesと答える人が多いでしょう．

この判断は，それぞれのクラスの起こりやすさの確率に基づいたものです，この入力を観測する前にもっているそれぞれのクラスの起こりやすさを，
事前確率 (prior probability) 
とよびます．
クラス$\omega_i$の事前確率は$P(\omega_i) ~~ (i=1,\dots,c)$ （ただし$c$はクラス数）と表します
．"
0405,"式(4.4)右辺第1項の条件付き確率$P(\bm{x} \vert \omega_i)$
を{ゆう|ど} (likelihood) 
とよびます．あるクラス$\omega_i$から特徴ベクトル$\bm{x}$が出現する\ruby{尤}{もっと}もらしさを表します．
結論として，事後確率が最大となるクラスは，尤度と事前確率の積を最大とするクラスを求めることによって得られます．"
0406,"しかし，一般の機械学習の問題では，どのクラスが出やすいかという事前確率や，各クラスから生じる特徴の尤もらしさを表す
尤度はわかりません．

そこで，この事前確率や尤度を計算する確率モデルを仮定し，そのパラメータを学習データに最も合うように調整することを考えます．
それぞれのクラスは，特徴ベクトルを生成する何らかの確率分布をもっていて，学習データはその確率分布から，各事例独立に
生成されたものと仮定します．この仮定を
i.i.d. (independent and identically distributed) 
と表記します．学習データ全体$D$が
生成される確率$P(D)$は，個々の事例$\{\bm{x}_1,\dots,\bm{x}_N\}$の独立性、すなわち i.i.d. を仮定すると，式(4.5)のように，個々の事例が生成される確率の積で求めることができます．

% equation 4.5

$P$は，データの生成確率を何らかのパラメータに基づいて計算するモデルです．ある程度複雑なモデルでは，パラメータが複数あることが一般的なので，これらのパラメータをまとめて$\bm{\theta}$と表記して明示すると，式(4.5)は式(4.6)のように書けます．"
0407,"こちらは，モデルのパラメータが与えられたときの，学習データ全体が生成される尤度を表しています．
ここで，確率は1以下であり，それらの全学習データ数回の積はとても小さな数になって扱いにくいので，式(4.6)の対数をとって計算します．式(4.7)で計算される値を対数尤度$\mathcal{L}(D)$とよびます．

% equation 4.7

この対数尤度の値は，大きければ大きいほど学習データがそのモデルから生成された確率が高い、ということがいえます．そして，学習データが，真のモデルから偏りなく生成されたものであると仮定すると，この方法で求めたモデルは真の分布に近い，と考えることができます．
したがって，式(4.7)を最大にするパラメータが求まればよいわけです．"
0408,"ここで，特徴ベクトルが1次元で，値として2値$x \in \{0,1\}$を取り，その出現がベルヌーイ分布
に従うと仮定します．そうすると，$P(x|\theta)$は，確率$\theta$をパラメータとして，式(4.8)のように書くことが
できます．

% equation 4.8

式(4.8)を使うと，対数尤度は，式(4.9)のように書くことが
できます．"
0409,"ここで，対数尤度$\mathcal{L}(D)$を最大にするパラメータ$\hat{\theta}$は，$d \mathcal{L}(D) / d\theta = 0$の解として
式(4.10)のように求めることができます．

% equation 4.10

式(4.10)右辺の分子は値1をとる事例数，分母は全事例数です．このように，推定するべき確率は，値1をとるデータ数の全データ数に対する割合という，ごく直観的な推定と一致します．
この推定法を
最尤推定法 (maximum likelihood estimation) 
とよびます．"
0410,"それでは，この最尤推定法を使って，式(4.4)の尤度を具体的に求める方法をみてゆきましょう．

多次元ベクトル$\bm{x}$を要素に分けて表記すると，式(4.11)のようになります．

% equation 4.11

尤度$ P(x_{1}, \dots, x_d \vert \omega_i)$を統計で求めるためには，学習データ中からクラス$\omega_i$に属するデータを取り出し，そのデータに対してすべての特徴値の組み合わせが，それぞれ何回起こっているかをカウントすることになります．式(4.1)のところでの考察に比べると，条件部にあてはまるデータがない，ということはないので少しはましですが，結論部にあてはまるデータが，統計をとれるほとに十分に揃っているということはなかなか望めそうにありません．

そこで，各特徴はほかの特徴とは独立に値を決定するものと仮定をすると，特定の特徴について，特定の値をとるデータを集めることになるので，すべての特徴値の組み合わせに対するデータよりはかなり少ない量のデータで学習ができます．このような，特徴の独立性を仮定した識別法を
ナイーブベイズ識別法 (naive Bayes classifier)
または単純ベイズ識別法とよびます．識別の結果を$C_{\mbox{NB}}$とすると，ナイーブベイズ識別法は式(4.12)のように定義できます．

% equation 4.12

この$P(x_{j} \vert \omega_i)$であれば，クラス$\omega_i$のデータの中で，特徴値$x_{j}$をとるデータの頻度を数えることで確率を推定する，最尤推定をおこなうことで求めることができます．"
0411,"しかし，このように少ないデータでも学習が行えるように尤度計算の方法を単純にしても，学習データが少ないがゆえに生じる問題がまだあります．

$n_i$を「学習データ中で，クラス$\omega_i$に属するデータ数」，$n_{j}$を「クラス$\omega_i$のデータ中で，ある特徴が値$x_j$をとるデータ数」としたとき，ナイーブベイズ識別に用いる尤度は，式(4.13)で最尤推定されます．

% equation 4.13

ここで$n_{j}$が0の場合，この特徴値に対する尤度が$0$になり，その結果，この特徴値を含むすべての事例の確率が$0$になるという
ゼロ頻度問題
が生じます．
たとえば，表3.3に示したweather.nominalデータでは， play=no のクラスで，outlook=overcast を特徴とする事例がありません．

このようなゼロ頻度問題へ対処するには，確率の
m推定
という考え方を用います．
これは$m$個の仮想的なデータがすでにあると考え，それらによって各特徴値の出現は事前にカバーされているという状況を設定します．
各特徴値の出現割合$p$を事前に見積り，事前に用意する標本数を$m$とすると，尤度は式(4.14)で推定されます．このときの$m$を，等価標本サイズとよびます．

% equation 4.14

この工夫によって，$n_j = 0$のときでも，式(4.14)の右辺の値が0にならず，ゼロ頻度問題が回避できることになります．"
0412,"ナイーブベイズ識別器の「すべての特徴が，あるクラスのもとで独立」であるという仮定は，一般的には成り立ちません．
だからといって，必ずしもすべての特徴が依存し合っているということでもありません．あいだをとって，「特徴の部分集合が，あるクラスのもとで独立である」と仮定することが現実的です．このような仮定を表現したものが，ベイジアンネットワークです．

ベイジアンネットワークとは，確率的に値を変化させる変数（以下，確率変数とよびます．本書の設定では，特徴やクラスにあたります）をノード，それらの間の依存関係をアーク（片方向の矢印）でグラフィカルに表した確率モデルです．依存関係は，アークに付随する条件付き確率表で定量的に表現されます．

ベイジアンネットワークでは，確率変数間に条件付き独立の仮定を設けます．この仮定は，

確率変数（ノード）の値は，その親（アークの元）となる確率変数の値以外のものには影響を受けない

というものです．数式で表すと，確率変数の値$\{z_1,\dots,z_n\}$の結合確率は，以下のように計算されます．

% equation 4.15

ただし$\mbox{Parents}(Z_i)$は，値$z_i$をとる確率変数を表すノードの親ノードの値です．親ノードは複数になる場合もあります．
これらのパターンを組み合わせて，図4.9のようなベイジアンネットワークを構成することができます．

% figure 4.9

ベイジアンネットにおけるノードの値の確率計算は，この3パターンと，そのバリエーション（親や子の数が異なる場合）だけなので，
この計算を順に行うことで，ネットワーク全体の確率計算が行えます．"
0413,"上記の例は，普通の条件付き確率をベイジアンネットワークで表現したものです．しかし，ベイジアンネットワーク
の利点は，変数間の独立性を表現できることです．以下では，独立性を表現する基本パターンと，それぞれの
確率計算の例を示します．

最初のパターンはHead-to-tail connectionで，これは三つのノードが直線上に並んだものです．
図4.6に，「曇っている」(Cloudy)，「雨が降った」(Rain)，「芝生が濡れている」(Wet grass)
がHead-to-tail connectionでつながっている例を示します．

% figure 4.6

これは，真ん中のノードの値が与えられると，左のノードと右のノードが独立になるパターンです．
もし，Rainの値が定まっていれば，Wet grassの値はCloudyの値とは無関係に，RainからのWet grassへのアークに付随している
条件付き確率表のみから定まります．一方，Rainの値がわからないときは，Rainの値はCloudyの値に影響され，
Wet grassの値はRainの値に影響されるので，CloudyとWet grassは独立ではありません．

何も情報がない状態での「芝生が濡れている」確率は以下のようになります．
まず，「曇っている」の事前確率$P(C)$を使って「雨が降った」確率$P(R)$を求め，それを使って
「芝生が濡れている」確率$P(W)$を求めます．

% align*

ここで，「曇っている」ことが観測されたとします．そうすると，その条件の下で「芝生が濡れている」確率$P(W|C)$は，
以下のようになります．

% align*

つまり，「曇っている」ことの観測が，「芝生が濡れている」確率を変化させているので，これらは独立していない
ことになります．

なお，確率伝播の計算は，逆方向にも可能です．「芝生が濡れている」ことがわかったときに，
その日が「曇っている」確率は以下のようになります．"
0414,"二つめの独立性のパターンは，Tail-to-tail connectionで，二つのノードが親ノードを共有する
パターンです．図4.7に「スプリンクラーが動作」(Sprinkler)，「雨が降った」(Rain)
が共通の親ノード「曇っている」(Cloudy)をもつパターンを示します．

% figure 4.7

このパターンで，たとえば「雨が降った」 ことがわかると，「曇っている」確率は，事前確率$P(C)=0.5$から以下の
$P(C|R)$のように変化します．

% align*

このことによって，「スプリンクラーが動作」の確率も変化するので，「雨が降った」と「スプリンクラーが動作」
は独立ではありません．

一方，Cloudyの値がわかると，Sprinkler，Wet Grassそれぞれの値は，その条件付き確率表だけから求まるので，
それぞれ独立になります．すなわち，このTail-to-tail connectionパターンでは，親ノードの値が与えられると，
子ノードが独立になります．"
0415,"最後は，子ノードを共有するHead-to-head connectionパターンです．このパターンの例を図4.8に示します．

% figure 4.8

この場合，「スプリンクラーが動作」と「雨が降った」は，共有する祖先ノードを持たないので，独立です．
しかし，「芝生が濡れている」の値が与えられると，独立ではなくなります．

このことを計算によって確認してゆきましょう．
まず，$P(W)$の事前確率を計算します．$S,R$それぞれのtrueまたはfalseの組合せが起こる確率を事前確率から求め，
条件付き確率表の値と掛け合わせたものを，すべての組合せに対して計算するので，少し面倒な計算になります．

% align*

同様にして，$P(W|S), P(W|R)$を求めます．

% align*

% align*

この$P(W)$と$P(W|S)$を使って，「芝生が濡れている」ことが観測されたときの「スプリンクラーが動作」の確率$P(S|W)$を計算します．

% align*

また，「雨が降った」と「芝生が濡れている」の両方が観測されたとき，「スプリンクラーが動作」の確率$P(S|R,W)$は
% align*
になります．条件部に$R$が加わることで，条件付き確率の値が変わっているので，Wet grassの値が与えられると，RainとSprinklerは独立ではなくなったといえます．

前二つの独立性の議論と比べて，直観的にわかりにくいのですが，「芝生が濡れている」ことがわかっていて，
「雨が降った」が否定されるのなら，「スプリンクラーが動作」の確率が高くならざるを得ないとみれば，納得がゆくと
思います．"
0416,"ここでは，ベイジアンネットワークがすでにできている，すなわち図4.9に示したようなネットワーク
の構造と，全アークに対応する条件付き確率表が得られているものとして，それを用いて識別を行う手順
を説明します．一般にクラスは親ノードに，特徴は子孫ノードに配置します．
求めるものは，特徴を現すノードの値が与えられたもとで，クラスを表すノードが真となる確率ですが，ここではネットワーク中の一部のノードの
値が与えられたときに，値が与えられていないノードが真となる確率を求める問題に一般化して考えます．

ここで，値が真となる確率を知りたいノードが表す変数を，目的変数とよびます．
目的変数以外のすべての変数の値が観測された場合（実際は，目的変数の親ノードの値が観測された場合，あるいは，さらなる親ノードの値から計算可能な場合）は，
目的変数から遠い順に条件付き確率表を使ってノードの値を計算することで，目的変数の
値が求まります．しかし，効率を求める場合や，一部のノードの値しか観測されなかった場合
にも対応できる方法として，確率伝播による計算法があります．
このようにノード間の独立性を使いながら，確率を伝搬させて任意のノードの確率を求めることができます．ただし，
この方法はアークを無向とみなした結合を考えたときに，ループが形成されていれば値が収束しないことがあるので，
適用することができません．そのような場合は，確率的シミュレーションも用いられます．"
0417,"最後に，ベイジアンネットワークの学習について説明します．ベイジアンネットワークにおいて学習するべき項目
は，ネットワークの構造とアークの条件付き確率表です．

まず，ネットワークの構造が得られているものとして，アークの条件付き確率表を得る方法について説明します．

学習データにすべての変数の値が含まれる場合は，単純ベイズ法と同様な数え上げによって確率値を決めることができます．
ここでも，ゼロ頻度問題を回避するために，データカウント数の初期値を一定値にしておくなどの
工夫が必要になります．一方，学習データに値が観測されない変数がある場合は，適当な初期値を設定して，
第5章で説明する最急勾配法により学習することになります．

また，ベイジアンネットワークの構造の学習は，そのネットワークによって計算される式(4.7)の対数尤度が大きくなるように，
アークを探索的に追加してゆく方法が考えられます．その基本的な方法がK2アルゴリズムで，概要は以下のようになります．ここで$Node$は特徴集合とクラスからなるノード全体の集合を表します．

% algorithm 4.2

一般に，複雑なネットワークのほうが対数尤度は大きくなるので，このアルゴリズムは簡単に過学習に陥りやすいといわれています．過学習への対処法としては，親ノードの数をあらかじめ制限する方法が提案されています．"
0501,"この章では，前章で学んだ統計モデルによる識別法で，数値を要素とする特徴ベクトルを識別する
問題に取り組みます．数値を要素とする特徴ベクトルに対する識別問題は，一般にはパターン認識とよばれます．

第3章と第4章では，カテゴリ特徴に対する識別問題を扱いました．続いて本章では，数値を要素とする特徴ベクトル$\bm{x}$に対する識別問題を扱います（図5.1）．"
0502,"識別問題は教師あり学習なので，学習データは特徴ベクトル$\bm{x}_i$と正解情報であるクラス$y_i$のペアからなります．

カテゴリ特徴との違いは，特徴ベクトルの要素が数値なので，各要素を軸とする空間を考えることができる点です．特徴の種類数を
$d$個とすると，この空間は$d$次元空間になります．この空間を，
特徴空間
とよびます．学習データ中の各事例は，特徴空間上の点として表すことができます（図5.2）．

もし，特徴抽出段階で適切な特徴が選ばれているならば，図5.3のように，学習データは特徴空間上で，クラスごとにある程度まとまりを構成していることが期待できます．そうでなければ，人間や動物が日常的に識別問題を解決できるはずがありません．このように考えると，数値特徴に対する識別問題は，クラスのまとまり間の境界をみつける，すなわち，特徴空間上でクラスを分離する境界面を探す問題として定義することができます．

境界面が平面や2次曲面程度で，よく知られた統計モデルがデータの分布にうまく当てはまりそうな場合は，本章で説明する統計モデルによるアプローチが有効です．

一方，学習データがまとまっているはずだといっても，それが比較的単純な識別面で区別できるほど，きれいには分かれていない場合もあります．その境界は，曲がりくねった非線形曲面になっているかもしれません．また，異なるクラスのデータが一部重なる部分がある可能性があります．そのような，非線形性を持ち，完全には分離できないかもしれないデータに対して識別を試みるには，次章以降で説明する二つのアプローチがあります．

一つは，学習データを高次元の空間に写すことで，きれいに分離される可能性を高めておいて，線形のモデルを使ってなるべく学習データに特化しすぎないような識別面を求めるという方法です．この代表的な手法が，第7章で説明するSVM（サポートベクトルマシン）です．もう一つは，非線形のモデルであらわした複雑な境界面のパラメータを，学習データとの誤差がなるべく少なくなるように調整する方法です．この代表的な手法が第8章と第9章で説明するニューラルネットワークです．"
0503,"第4章では，カテゴリ特徴に対する統計的識別手法を説明してきました．その基本的な考え方は，数値特徴に対しても
適用することができます．

数値特徴の場合のナイーブベイズ識別の結果を求める式は，式(5.1)のようになります．カテゴリ特徴の場合の式(4.12)とほとんど同じですが，尤度が離散事象に対する確率分布$P(x_j|\omega_i)$ではなく，数値に対する確率密度関数$p(x_j|\omega_i)$になっています．

事前確率$P(\omega_i)$に関しては，カテゴリ特徴のときと同様に，学習データ中のクラス$\omega_i$に属するデータを数える最尤推定で求めればよいので，とくに問題はありません．

しかし，尤度$p(x_j \vert \omega_i)$に関しては，求めるものが「クラス$\omega_i$のデータの属性$a_j$が値$x_j$となる確率」で，$x_j$が連続値なので，頻度を数えるという方法を用いることはできません．

そこで，数値特徴に対しては，尤度を計算する確率密度関数に適切な統計モデルをあてはめ，そのモデルのパラメータを学習データから推定する
という方法を取ります．数値データに対する統計的モデル化は，それだけで一冊の本になるぐらい奥が深い問題です．
本書では，教師なし学習におけるモデル推定のところで少し詳しく説明するので，ここでは，最も単純な方法で
考えます．

様々な数値データに対して多く用いられる統計モデルが正規分布です．正規分布は図5.4に示すような釣り鐘型をした分布で，身長・体重の分布や，多人数が受けるテストの点数の分布などがよく当てはまります．

1次元データの正規分布は，式(5.2)のようになります．

ここで，$\mu$は正規分布の平均値，$\sigma$は標準偏差です．この二つを正規分布のパラメータとよび，パラメータの値が決まると，$p(x)$の関数形が決まります．

このような仮定をおいたときの学習は，正規分布の平均値と標準偏差を学習データから推定するという問題になります．
これは，カテゴリカルデータの頻度による推定と同様の考え方で，学習データの平均値をモデルの平均値，学習データの標準偏差をモデルの標準偏差とすることで，最尤推定になります．"
0504,"ここで，式(4.2)に基づいて得られた事後確率の計算式を，記号を変えてもう一度見直してみます．

式(5.3)の分子は，
生成モデル
とよばれる考え方で解釈することができます．まず，あるクラス$\omega_i$が確率$P(\omega_i)$で選ばれ，そのクラスから特徴ベクトル$\bm{x}$が確率$p(\bm{x} \vert \omega_i)$に基づいて生成されたという考え方です．これは式(5.4)の分子である特徴ベクトルとクラスの同時確率$p(\omega_i, \bm{x})$を求めていることになります．

この生成モデルアプローチは，（学習データとは別に，何らかの方法で）事前確率がかなり正確に分かっていて，それを識別に取り入れたい場合には有効です．しかし，そうでない場合は，推定するべきパラメータは，$P(\omega_i|\bm{x})$を直接推定するよりも増えてしまいます．同じ量のデータを用いて複数のパラメータを推定する場合，パラメータの量が増えるほど，問題が難しくなるのが一般的です．つまり，生成モデルアプローチは，本来解くべき問題を，あえて難しい問題にしてしまっているのではないかという疑問が出てくるわけです．

この問題への対処法として，次節では，$P(\omega_i|\bm{x})$を直接推定する方法について説明します．"
0505,"$P(\omega_i|\bm{x})$をデータから直接推定するアプローチは，
識別モデル
とよばれます．
識別モデルと近い考え方で，
識別関数法
というものがあります．これは，第1章で説明した関数$\hat{c}(\bm{x})$を，確率分布などの制約を一切考えずに，データだけに注目して構成する方法です．確率・統計的な手法が主流となる前の時代，すなわちコンピュータがそれほど高速でなく，大規模なデータを用意することが難しかった時代には，この識別関数法はパターン認識の主流の手法でした．

最も古典的な識別関数法の手法は，パーセプトロンとよばれるもので，生物の神経細胞の仕組みをモデル化したものでした．以後，このパーセプトロンを多層に重ねたニューラルネットワーク（多層パーセプトロンともよばれます）について，理論的な研究が進められ，1980年代に誤差逆伝播法によって学習が可能であることが多くの研究者に認知されると，一時的にブームを向かえることになります．しかし，その後は，統計的手法の
発展や，同じ識別関数法でもサポートベクトルマシンの優位性が強調されるにつれて，次第に過去の手法と見なされるようになっていました．

ところが近年，第9章で紹介する深層学習が驚異的な成果を上げていることで，再度注目されるようになっています．"
0506,"まず，最も基本的な識別関数法である誤り訂正学習から説明を始めます．

1943年に，McCullochとPittsは神経細胞の数理モデル（図5.5）を組み合わせて，任意の論理関数が計算可能であることを示しました．

図5.5に基づいた計算モデルを単層パーセプトロンとよびます．このモデルを単独で考えると，入力の重み付き和を計算して，その値と閾値を比べて出力を決めるということをしています．閾値との比較をしている部分は，$x_0 = 1$という固定した入力を仮定し，この入力に対する重みを$w_0 = - \theta$とすることで，その他の入力の重み付き和に組み込むことができます．これは$d$次元の特徴空間上で，$g(\bm{x}) = w_0+w_1 x_1+\dots+w_d x_d = 0$という識別超平面を設定し，入力がこの識別超平面のどちら側にあるのかを計算していることと等価になります．

もし，与えられた学習データが特徴空間上で線形分離可能ならば（超平面で区切ることができるならば），以下に示す
パーセプトロンの学習アルゴリズム
で，線形分離面を見つけることができます．"
0507,"ここで，$\bm{x}$は特徴ベクトルに$x_0=1$を加えた$d+1$次元ベクトル，$\bm{w}$は$d+1$次元の重みベクトルとします．
また，$\eta$は学習係数で，適当な小さい値を設定します．
このアルゴリズムは，学習データが線形分離可能な場合には必ず
識別境界面を見つけて停止します．これを
パーセプトロンの収束定理
とよびます．一方，
学習データが線形分離不可能な場合にはこのアルゴリズムを適用することが
できません．全ての誤りがなくなることが学習の終了条件なので，データが線形分離不可能な場合は
このアルゴリズムは停止しません．"
0508,"前節の誤り訂正学習は，学習データが線形分離可能であることを前提にしていました．しかし，現実の
データではそのようなことを保証することはできません．むしろ，線形分離不可能な場合の方が多いと
思われます．

そこで，統計的手法での対数尤度最大化のように，識別関数法でもなんらかの基準で識別関数の
良さを定量的に表して，それを最大化するという方法で，線形分離不可能なデータにも対処することを考えます．

しかし，識別関数の「良さ」を定義するよりは，「悪さ」を定義する方が簡単なので，
識別関数が誤る度合いを定量的に表して，それを最小化するという方法を考えます．

個々のデータに対する識別関数の「悪さ」は，その出力と教師信号との差で表すことができます．
しかし，データ集合に対して，この「悪さ」を足し合わせてしまうと，出力よりも教師信号が大きい場合と，
出力よりも教師信号が小さい場合の効果が打ち消し合ってしまいます．そこで，識別関数の出力と
教師信号との差の2乗を，全データに対して足し合わせたものを識別関数の「悪さ」と定義し，この量を
二乗誤差と呼びます．この二乗誤差を最小にするように識別関数を調整する方法が，最小二乗法による学習
です．"
0509,"求める関数を線形であると仮定すると，式(5.5)のように表現できます．

この式の係数$\bm{w}$を学習データから推定します．推定の基準として，式(5.5)で
算出された出力と，教師信号との誤差がなるべく少なくなるようにします．
誤差は式(5.5)の係数$\bm{w}$の値によって決まるので，$E(\bm{w})$と表現し，
以下の式で求めます．

ここで，扱いにくい総和演算を消すために，学習データを行列で，教師信号をベクトルであらわします．

$d$次元列ベクトルの学習データ$\bm{x}_i$を$N$個横に並べた行列を$\bm{X}$と表し，
教師信号$y_i$の値を並べた列ベクトルを$\bm{y}$，係数を並べた列ベクトルを$\bm{w}$とすると，
誤差は以下のようになります．

この値が最小になるのは，$\bm{\beta}$で微分した値が0となる極値をとるときなので，
求める係数は以下のようになります．

すなわち，二乗誤差を最小にする重み$\bm{w}$は，学習データから解析的に求めることができます．
また，学習データ数や特徴の次元数が大きく，逆行列を求めることが困難な場合は，5.3.5項で説明する
確率的最急勾配法を用いて，重み$\bm{w}$を学習します．"
0510,"次に，この識別関数法の考え方を確率モデルに適用する，識別モデルの考え方を説明します．

第4章で説明したように，データから直接に頻度を数えて事後確率$P(\omega_i|\bm{x})$を求めることはできません．
そこで，識別モデルでは，この事後確率を特徴値の組み合わせから求めるようにモデルを作ります．
つまり，特徴ベクトル$\bm{x$}が与えられたときに，その$\bm{x}$の値を用いて，何らかの方法で，
出力$y$の確率分布を計算するメカニズムをモデル化します．

いま，2値分類問題における特徴ベクトル$\bm{x}=(x_1, \dots, x_d)^T$に対して，各特徴の重み付き和
$w_1 \cdot x_1 + \dots + w_d \cdot x_d$を考え，正例に関しては正の値，負例に関しては負の値を出力するように
重みを調整することを考えます．ただし，これでは原点$\bm{x} = \bm{0}$に対して
判定ができないので，定数$w_0$をパラメータとして加え，改めて$g(\bm{x})=w_0 + w_1 \cdot x_1 + \dots + w_d \cdot x_d 
= w_0 + \bm{w} \cdot \bm{x}$

と定義します．

ここで，$g(\bm{x})=0$とおいたものは，式の形から$d$次元空間上の平面を表しています．もし，この平面が上記のように
ふるまうように調整ができたとすると，この平面上にある点は，どちらのクラスとも判別がつかず，
平面の正の側（$g(\bm{x})>0$となる側）の空間に正例，平面の負の側（$g(\bm{x})<0$となる側）の空間に負例の空間ができるはずです．
このように，特徴空間上でクラスを分割する面を
識別面
とよびます．
また，それぞれの点の判定の確からしさは，識別面からの距離に反映されます．"
0511,"ただし，このままでは，$g(\bm{x})$は$\bm{x}$の値次第で，極端に大きな（あるいは小さな）値となる可能性があり，確率と対応づけることが難しくなります．$g(\bm{x})$の望ましいふるまいは，出力範囲が0以上1以下ので，正例に属する$\bm{x}$には1に近い値を，負例に属する$\bm{x}$には0に近い値を出力することです．このようなふるまいは，変換$1/(1+e^{-g(\bm{x})})$を行い，
これを式(5.10)に示すように事後確率$p(\oplus|\bm{x})$（ただし，$\oplus$は正のクラス）と対応付けることで実現できます．

この場合，$\bm{x}$が負のクラスになる確率は$p(\ominus|\bm{x}) = 1 - p(\oplus|\bm{x})$（ただし，$\ominus$は負のクラス）
で求められます．

式(5.10)はシグモイド関数（図5.6）とよばれるもので，$g(\bm{x}) = w_0+\bm{w}\cdot\bm{x}$がどのような値をとっても，シグモイド関数の値は0から1の間となります．また，$g(\bm{x})=0$のとき，式(5.10)の値は0.5となり，これは
確率を表現するのに適しています．"
0512,"ロジスティック識別器は重み$\bm{w}$（これ以降は，説明を簡潔にするために$\bm{w}$は$w_0$を含みます）をパラメータとする確率モデルとみなすことができます．
そして，このモデルに学習データ$D$中の$\bm{x}_i$を入力したときの出力を$o_i$とします．望ましい出力は，正解情報$y_i$です．2値分類問題を仮定し，正例では$y_i=1$，負例では$y_i=0$とします．

作成したモデルがどの程度うまく学習データを説明できているか，ということを評価する値として，尤度を式(5.11)
のように定義します．

正例のときは$o_i$がなるべく大きく，負例のときは$1-o_i$がなるべく大きく（すなわち$o_i$がなるべく小さく）なるようなモデルが，よいモデルだということを表現しています．

尤度の最大値を求めるときは，計算をしやすいように対数尤度にして扱います．

最適化問題をイメージしやすくするために，この節では，対数尤度の負号を反転させたものを誤差関数$E(\bm{w})$と定義し，以後，誤差関数の最小化問題を考えます．

これを微分して極値となる$\bm{w}$を求めます．モデルはロジステック識別器なので，その出力である$o_i$はシグモイド関数で与えられます．

シグモイド関数の微分は以下のようになります．

モデルの出力は重み$\bm{w}$の関数なので，$\bm{w}$を変えると誤差の値も変化します（図5.7）．このような問題では，
最急勾配法
によって解を求めることができます．最急勾配法とは，
最小化したい関数の勾配方向へ，パラメータを少しずつ動かすことを繰り返して，最適解へ収束させる方法です．この場合は
パラメータ$\bm{w}$を誤差の$E(\bm{w})$の勾配方向へ少しずつ動かすことになります．この「少し」という量を，学習係数
$\eta$と表すことにすると，最急勾配法による重みの更新式は式(5.16)のようになります．"
0513,"そして，誤差$E(\bm{w})$の勾配方向の計算は以下のようになります．$x_{ij}$は，$i$番目の学習データの$j$次元目の値です．

したがって，重みの更新式は以下のようになります．

最急勾配法は，重みの更新量があらかじめ定めた一定値以下になれば終了です．"
0514,"ここで説明した最急勾配法は，最適化問題によく用いられる手法ですが，いくつか欠点もあります．

まず，式(5.17)からわかるように，全データに対する誤差を計算してから重みを更新するので，
一回の重みの更新に時間がかかり，データ数が多いと収束が遅くなります．

また，最大の欠点として，最適化対象の関数がいくつかの局所的最適解をもつとき，その局所的最適解
に陥りやすいといわれています．対処法としては，初期値を変えて何回か試行するという方法が取られていますが，
データの次元数が高い場合，その特徴空間にまんべんなく初期値を設定することは難しくなります．

これらの問題に対処するために，重みの更新を全データで一括におこなうのではなく，ランダムに学習データを一つ選び，その学習データに対して重みを更新する
という方法が考えられます．この方法を
確率的最急勾配法
とよびます．重みの更新式は，式(5.18)のようになります．"
0601,"本章で扱う回帰問題は，過去の経験をもとに今後の生産量を決めたり，信用評価を行ったり，価格を決定したりする
問題です
過去のデータに対するこれらの数値が学習データの正解として与えられ，未知データに対しても
妥当な数値を出力してくれる関数を学習することが目標です．

回帰問題は，正解付きデータから，「数値特徴を入力として数値を出力する」関数を学習する問題と定義できます
(図6.1)．"
0602,"関数を学習するためのデータは，すべての要素が数値である特徴ベクトルと，その出力値（スカラーの場合も，
ベクトルの場合もあります）の対として与えられます．

% equation 6.1

識別問題との違いは，正解情報$y$が数値であるということです．特に数値型の正解情報のことを
ターゲット
とよびます．

しかし，回帰と
「数値特徴を入力としてクラスラベルを出力する」識別問題との境界はそれほど明確ではありません．
例えば，クラスによって異なる値をとるクラス変数を導入し，入力からクラス変数の値を予測する問題と考える
と，識別問題を回帰問題として考えることもできます．

実際，カーネル法など共通して使われる手法も多くあり，混乱しそうになってしまうのですが，
まずはここでは「数値特徴を入力として数値を出力する」手法の習得に集中し，その全体像が
見えてから，他の問題との関係を考えてゆきましょう．"
0603,"まず，最も単純な，入力も出力もスカラーである場合の回帰問題（図6.2）を考えましょう．

% figure 6.2

この学習データから，入力$x$を出力$y$に写像する関数$\hat{c}(x)$を推定します．
図6.2のデータからは，入力$x$が大きくなると，出力$y$も大きい値になる傾向が
見えます．そこで，この傾向を直線であらわして，入力$x$と出力$y$を関係付けることを試みます．


もし学習データのすべての点が，その上にあるように直線を決めることができれば，これで問題は
終わりなのですが，通常そのようなことはありません．そこで，図6.3のようになるべく誤差の
少ない直線を求めることとします．

% figure 6.3

そうすると，ここでの定式化は5.3.2項で説明した最小二乗法による学習と等しくなります．
違いは，識別問題における教師信号$y_i$が1または0であったのに対して，回帰問題の教師信号$y_i$が
連続値であるということですが，学習アルゴリズム自体は変更なく適用することができます．

回帰式を式（6.2)

% equation　6.2

とする．"
0604,"誤差の二乗和は以下のように

% align 6.3, 6.4

なります．ただし，$\bm{X}$は1列目のすべての要素が1，2列目$i$行目の要素が$x_i$であるパターン行列，$\bm{W}$は，$(w_0, w_1)^T$です．

式(6.4)を$\bm{w}$で微分したものを$0$とおいて解くと，式(6.5)

% equation 6.5

となります．このような線形回帰式の求め方は，入力$\bm{x}$が一般の$d$次元の場合も，そのまま通用します．

解が解析的に求まってしまい，探索や最急勾配法による逐次的な修正も行っていないので，何か
機械学習という感じはしませんが，一応これは，学習データから得られる最も誤差の小さい線形回帰式です．"
0605,"ここでは回帰モデルの評価について考えます．
教師付き学習においては，未知データに対する
誤差が問題となります．この回帰式は未知データに対してもうまく値を予測してくれるのでしょうか．

回帰問題の評価は，交差確認法との相性はあまりよくありません．識別問題では，交差確認に用いるデータの部分集合は，そこに含まれるクラスの割合が，全体の割合と整合するように分割すれば，一回ごとの評価値がそれほど極端にはぶれず，ある程度適切な評価が行えます．しかし，回帰では何をもって部分集合の構成が近いかを定義することが難しくなります．したがって，計算能力に余裕があれば，一つ抜き法で評価することをお勧めします．

そこでの評価指標は，学習の基準に合わせると平均二乗誤差ということになります．しかし，この値はデータが異なれば，スケールがまったく異なるので，結果がよいものかどうか直観的にはわかりにくいものです．そこで，回帰の場合は，正解と予測とがどの程度似ているかを表す相関係数や，式(6.6)で計算できる決定係数で評価します．決定係数は，「正解との離れ具合」と「平均との離れ具合」の比を1から引いたものですが，式変形により相関係数の二乗と一致するので，$R^2$とも表記されます．"
0606,"次に，線形回帰式の重みに注目します．

一般的に，入力が少し変化したときに，出力も少し変化するような線形回帰式が，汎化能力という点では望ましいと思われます．このような性質を持つ線形回帰式は，重みの大きさが全体的に小さいものです．逆に，重みの大きさが大きいと，入力が少し変わるだけで出力が大きく変わり，そのように入力の小さな変化に対して大きく変動する回帰式は，たまたま学習データの近くを通っているとしても，未知データに対する出力はあまり信用できないものだと考えられます．

また，重みに対する別の観点として，予測の正確性よりは学習結果の説明性が重要である場合があります．製品の品質予測などの例を思い浮かべればわかるように，多くの特徴量からうまく予測をおこなうよりも，どの特徴が製品の品質に大きく寄与しているのかを求めたい場合があります．線形回帰式の重みとしては，値として0となる次元が多くなるようにすればよいことになります．

つまり，回帰式中の係数$\bm{w}$に関して，大きな値を持つものがなるべく少なくなる，あるいは値0となるものが多くなるような方法が必要になります．そのための工夫を
正則化
とよび，誤差の式に正則化項と呼ばれる項を追加することで実現します．

パラメータ$\bm{w}$の二乗を正則化項とするものを
Ridge回帰
とよびます．
Ridge回帰に用いる誤差評価式を式(6.7)に示します．
ここで，$\lambda$は正則化項の重みで，大きければ性能よりも正則化の結果を重視，小さければ性能を重視するパラメータとなります．

% equation 6.7

最小二乗法でパラメータを求めたときと同様に，$\bm{w}$で微分した値が0となるときの$\bm{w}$の
値を求めると，式(6.8)のようになります．

% equation 6.8

Ridgeは山の尾根という意味で，単位行列が尾根のようにみえるところから，このように名付けられたといわれています．
一般に，Ridge回帰は，パラメータの値が小さくなるように正則化されます．"
0607,"また，パラメータ$\bm{w}$の絶対値を正則化項とするものを
Lasso回帰
とよびます．一般に，Lasso回帰は値を0とするパラメータが多くなるように正則化されます．
英単語のlassoは「投げ縄」という意味で，投げ縄回帰と訳されることがあります．多くの特徴がひしめき合っている中に
投げ縄を投げて，小数のものを捕まえるというイメージをもってこのように呼ばれているのかもしれませんが，
Lassoのオリジナルの論文では，Lasso は least absolute shrinkage and selection operator の意味だと書かれています．

Lasso回帰に用いる誤差評価式を，式(6.9)に示します
．ここで，$\lambda$は正則化項の重みで，大きければ値を0とする重みが多くなります．

% equation 6.9

Lasso回帰の解は，原点で微分不可能な絶対値を含むため，最小二乗法のように解析的に求めることはできません．
そこで，正則化項の上限を微分可能な二次関数で押さえ，その二次関数のパラメータを誤差が小さくなるように
繰り返し更新する方法などが提案されています．"
0608,"Ridge回帰とLasso回帰における正則化の振る舞いの違いを図6.4に示します．

% figure 6.4

Ridge回帰は，図6.4(a)に示すように，パラメータの存在する範囲を円（一般の$d$次元では超球）の中に限定することで，それぞれの重みが大きな値を撮れないようにします．一般に，誤差関数の等高線との接点は，円周上の点になり，これが重みの値となります．一方，Lasso回帰は，パラメータの和が一定という
条件なので，図6.4(b)に示すように，それぞれの軸で角を持つ領域に値が制限されます．そして，その角のところで誤差関数の等高線と接します．
角の部分は，多くのパラメータが0になるので，これがLasso回帰の正則化に反映されます．"
0609,"前節で説明した最小二乗法は，回帰式を高次方程式に置き換えてもそのまま適用できます．一般に，特徴ベクトルに対して，
式(6.10)で示す基底関数を考え
，回帰式を式(6.11)のように定義すれば，係数が線形であるという条件の下で，最小二乗法が適用可能です．

% equation 6.10

% equation 6.11

複雑な関数を用いれば，真のモデルに近い形を表現できると考えられるので，より複雑な関数を用いればよいようにみえますが，
はたしてそうでしょうか．"
0610,"ここで，バイアスと分散の関係を考えてみます．バイアスは真のモデルとの距離，分散は学習結果の
散らばり具合と理解してください．

線形回帰式のような単純なモデルは，個別のデータに対する誤差は比較的大きくなってしまう傾向があるのですが，
学習データが少し変動しても，結果として得られるパラメータはそれほど大きく変動しません．これをバイアスは
大きいが，分散は小さいと表現します．
逆に，複雑なモデルは個別のデータに対する誤差を小さくしやすいのですが，学習データの値が少し異なるだけで，
結果が大きく異なることがあります．これをバイアスは小さいが，分散は大きいと表現します．

このバイアスと分散は，片方を減らせば片方が増える，いわゆるトレードオフの関係にあります．

このテーマは第3章の概念学習でも出てきました．概念学習では，バイアスを強くすると，安定的に
解にたどり着きますが，解が探索空間に含まれず，学習が失敗する場合がでてきてしまいました．一方，バイアスを弱くすると，
探索空間が大きくなりすぎるので，探索方法にバイアスをかけました．探索方法にバイアスをかけてしまうと，最適な概念（オッカムの剃刀に
従うと，最小の表現）が求めることが難しくなり，学習データのちょっとした違いで，まったく異なった結果が得られることが
あります．

回帰問題でも同様の議論ができます．線形回帰式に制限すると，求まった平面は，一般的には学習データ内の点をほとんど通らないので
バイアスが大きいといえます．一方，「学習データの個数-1」次の高次回帰式を仮定すると，「係数の数」と「学習データを回帰式に代入した制約の数」が等しく
なるので，連立方程式で解くことで，重みの値が求まります．つまり，「学習データの個数-1」次の回帰式は，全学習データを通る式に
することができます．これが第1章の図1.8(c)に示したような例になります．
この図からもわかるように，データが少し動いただけでこの高次式は大きく変動します．つまり，バイアスが弱いので
学習データと一致する関数が求まりますが，変動すなわち結果の分散はとても大きくなります．

このように，機械学習は常にバイアス－分散のトレードオフを意識しなければなりません．前節で説明した正則化は
モデルそのものを制限するよりは少し緩いバイアスで，分散を減らすのに有効な役割を果たします．"
0611,"回帰木とは，識別における決定木の考え方を回帰問題に適用する方法です．このような判断をしたから，この値が求まった
というように，結果に説明を付けやすくなるのが特徴です．

決定木では，同じクラスの集合になるように，特徴の値によって学習データを分割してゆく，
という考え方でした．それに対して，回帰では，出力値の近いデータが集まるように，特徴の値によって学習データを分割して
ゆきます．結果として得られる回帰木は図6.5のように，特徴をノードとし，出力値をリーフとするものに
なります．"
0612,"CART(classification and regression tree)は，木の構造を二分木に限定し
分類基準としてGini Impurity （ジニ不純度）を用いた決定木です．

Gini Impurityは識別問題にCARTを用いるときの分類基準で，式(6.12)を用いて
分類前後の集合のGini Impurity $G$を求め，式(6.13)で計算される改善度$\Delta G$が最も大きい
ものをノードに選ぶことを再帰的に繰り返します．

% equation 6.12

% equation 6.13

ただし，$T$はあるノードに属する要素の全体，$N(j)$は要素中のクラス$j$の割合，$T_L$は左の部分木，$P_L$は$T_L$に属するデータの割合（$L$を$R$に変えたものも同様）
を示します．"
0613,"このCARTを回帰問題に用いる時は，分類基準としてデータの散らばり$SS$の減り方$\Delta SS$が最大になるものを選びます．

% equation 6.14

% equation 6.15

ここで，$\tilde{y}$は$T$に属するデータの平均値です．
式(6.14)は木$T$に含まれるデータの分散を求めていることになるので，式(6.15)の基準は，
分割後の分散が最小となるような分割を求めていることに対応します．"
0614,"モデル木は，回帰木と線形回帰の双方のよいところを取った方法です．
CARTはリーフの値が定数であったのに対して，モデル木ではリーフの値を線形回帰式
とします．

回帰木と同じ考え方で，データの出力値が近い区間を切り出せる特徴を
選んでデータを分割してゆき，分割後のデータに対して線形回帰式を求めます．"
0615,
0616,"次に考えられる手法としては，
区分線形よりももっとなめらかな非線形関数を用いて回帰式を得られないか，ということになるのですが，
一般に非線形式ではデータにフィットしすぎてしまうため，過学習が問題になります．そこで，SVMのところで
も説明したカーネル法を使って，非線形空間へ写像した後に，線形識別を正規化項を入れながら学習するという
アプローチが有効になります．この手法については，文献\cite{akaho08}に詳しく書かれています．"
0701,"第7章から第10章では，教師あり学習全般に用いることができる，
発展的手法について説明します．大半は識別問題を題材に説明しますが，ほとんどの手法は，少しの
工夫で回帰問題にも適用できます．

この章では，サポートベクトルマシン(support vector machine: SVM)とよばれる学習手法について説明します．
扱う問題は，主として数値特徴に対する「教師あり・識別」問題です．

サポートベクトルマシンは，
線形のモデルを使ってなるべく学習データに特化しすぎないような識別面を求める方法です．そして，線形で識別できないデータに対応するために，誤識別に対してペナルティを設定することで対応する手法と，学習データを高次元の空間に写して，線形識別手法を適用するという手法について説明します．

いま，図7.1に示すような特徴空間上で平面によって分離することができる学習データが
あるとします．

この学習データに対して，識別率100\%で識別をおこなえる直線は無数に存在します．図7.1(a)，(b)の
どちらの識別境界線（図の実線）も，学習データに関しては識別率100\%ですが，未知データに対しては，図7.1(a)の識別境界線より図7.1(b)の識別境界線の方が，よい結果が出そうです．図の全体を眺めたとき，データの塊が見えたなら，その塊の
真ん中に位置する識別境界線が，最も汎化性能が高いことが予想できます．

この漠然とした「汎化性能の高さ」を定量的に表すために，識別境界線と最も近いデータとの距離を考えます．
この距離のことをマージン（図の実線と図の点線の距離）といいます．

マージンが広いほうが，学習データと識別境界線の間に未知データが入る余地があることになるので，
学習データからちょっとずれただけの未知データが，別クラスに識別されるということが少なくなります．これが，汎化性能の高さにつながります．

この学習データからのマージンが最大となる識別境界線（一般には識別超平面）を求める手法が
サポートベクトルマシン
です．"
0702,"まず，学習データが線形識別可能な状況で，マージンが最大となる識別面を求める方法を考えてゆきましょう．

使用するデータは，数値特徴に対して正解情報の付いたデータですが，
ここでは，2値分類問題に限定し，正解情報の値を正例$1$，負例$-1$とします．

識別面は平面を仮定するので，特徴空間上では式(7.1)で表現されます．

そうすると，$i$番目のデータ$\bm{x}_i$と，この識別面との距離$Dist({\bm{x}_i})$は，点と直線の距離の公式を用いて，式(7.2)のように計算できます．

ここで，式(7.1)の左辺は正例に対しては正の値，負例に対しては負の値を出力するようにその重みを調整した式ですが，
右辺の値が0なので，左辺を定数倍しても表す平面は変わりません．そこで，識別面に最も近いデータを
識別面の式に代入したときに，その絶対値が1になるように重みを調整したとします．

そうすると，式(7.2)，(7.3)より，学習パターンと識別面との最小距離は，以下のようになります．

式(7.4)がマージンを表すので，マージンを最大にする識別面を求める問題は，$||\bm{w}||$を最小化する
問題になります．ここで，最小化しやすいように，この問題を$||\bm{w}||^2$の最小化とします．

この式の形だけを見ると，$\bm{w}=\bm{0}$が最小解ですが，これでは識別面になりません．"
0703,"識別面として
すべての学習データを識別できるという式(7.5)の条件を加えます．

$y_i=1~or~-1$としていたので，正例・負例両方の制約を一つの式で表すことができました．

ここまでで，マージンを最大にする識別面を求める問題の定式化が終わりました．
式(7.5)の制約下での$||\bm{w} ||^2$の最小化問題になりました．この後，微分を利用して極値を求めて
最小解を導くので，乗数$1/2$を付けておきます．"
0704,"ここでは前節で定式化した問題を，ラグランジュの未定乗数法を用いて解決する方法を説明します．

ラグランジュの未定乗数法を用いると，$g(\bm{x})=0$という条件の下で$f(\bm{x})$の最小値（あるいは最大値）を求める問題は，$L(\bm{x}, \lambda)=f(\bm{x})-\lambda g(\bm{x})$ （ただし$\lambda$はラグランジュ乗数）という新しいラグランジュ関数を導入し，この関数の極値を求めるという問題に置き換えることができます．

ラグランジュ関数の$\bm{x}$に関する偏微分を0とすると，式(7.8)のようになります．
ここでは，ラグランジュの未定乗数法を不等式制約条件で用います．そうすると，式(7.6)，式(7.7)の
制約付きの最小化問題は，ラグランジュ乗数$\alpha_i$を導入して，以下の関数$L$の最小値を求めるという問題に置き換えることができます．"
0705,"最小値では$L$の勾配が0になるはずなので，以下の式が成り立ちます．

これを式(7.9)に代入して，以下の式を得ます．

次はこれを最小化するわけですが，これは$\alpha_i$に関する2次計画問題と呼ばれるものです．したがって，
Scilabなどの数値計算ソフトウェアを使って簡単に解くことができます．

これを解くと，$\alpha_i \neq 0$となるのは，サポートベクトル
に対応するもののみで，大半は$\alpha_i = 0$となります．
この$\alpha_i$を式(7.11)に代入して，$\bm{w}$を得ることができます．"
0706,"また，$w_0$は，$\bm{x}_{+}, \bm{x}_{-}$をそれぞれ正例，負例に属するサポートベクトルとすると，以下の式で求めることが
できます．

この方法で，学習データが線形分離可能な場合にはマージンを最大にする決定境界が見つかります．"
0707,"次に，学習データが線形分離可能でない場合を考えます．前節と同様に線形識別面を設定するのですが，その際，
間違ったデータがあってもよいので，それらが識別面からあまり離れていないような識別面を選ぶこととします．"
0708,"式(7.7)がすべてのデータを正しく識別できる条件なので，この制約を弱める変数（スラック変数とよびます）$\xi_i ~ (\ge 0)$を
導入して，$i$番目のデータが制約を満たしていない程度を示します．

$\xi_i$は制約を満たさない程度を表すので，小さい方が望ましいものです．この値を上記SVMのマージン最大化
（$|| \bm{w} ||^2$の最小化）問題に加えます．
これをラグランジュの未定乗数法で解くと，結論として同じ式が出てきて，ラグランジュ乗数$\alpha_i$に
$0 \le \alpha_i \le C$という制約が加わります．"
0709,"ここで$C$は制約を満たさないデータをどの程度の重みで組み込むかを決める定数で，$C$が大きければ影響が大きく，
$C$が小さければほとんど無視するような振る舞いになります．"
0710,"一般に，特徴空間の次元数$d$が大きい場合は，データがまばらに分布することになるので，線形分離面が存在する可能性が高くなります．
そこで，この性質を逆手にとって，低次元の特徴ベクトルを高次元に写像し(図7.3参照)，線形分離の可能性を高めてしまい，その高次元空間上でSVMを使って識別超平面を求めるという方法が考えられます．

この方法は，むやみに特徴を増やして次元を上げる方法とは違います．識別に役立つ特徴で構成された$d$次元空間
に対して，もとの空間におけるデータ間の距離関係を保存する方式で高次元に非線形変換したならば，その高次元空間上での線形識別器の性能は，もとの空間での複雑な非線形識別器の性能に相当することがわかっています．一方，識別に無関係な特徴を持ち込むと，
データが無意味な方向に\ruby{疎}{まばら}に分布し，もとの分布の性質がこわされやすくなってしまいます．

しかし問題は，もとの空間におけるデータ間の距離関係を保存するような，そんな都合の良い非線形写像が
見つかるかということです．"
0711,"ここで，もとの特徴空間上の2点$\bm{x}, \bm{x}'$の距離に基づいて
定義されるある関数$K(\bm{x}, \bm{x}')$を考えます．この関数を
カーネル関数
とよびます．
そして，非線形写像を$\phi$としたときに，以下の関係が成り立つことを仮定します．

つまり，もとの空間での2点間の距離が，非線形写像後の空間における内積に反映されるという形式で，
近さの情報を保存します．"
0712,"さて，カーネル関数が正定値関数という条件を満たすときには，このような非線形変換$\phi$が存在することが
わかっています．そのようなカーネル関数の例としては，以下のような多項式カーネル関数や

以下のようなガウシアンカーネル関数

などがあります．"
0713,"ここで，簡単なカーネルについてその非線形変換$\phi$を求めてみましょう．特徴ベクトルを2次元として多項式カーネル(p=2)を展開します．

したがって，$\bm{x}=(x_1, x_2)$のとき，$\phi(\bm{x})=(x_1^2, x_2^2, \sqrt{2} x_1 x_2, \sqrt{2} x_1, \sqrt{2} x_2, 1) )$
となります．この変換の第3項に注目してください．特徴の積の項が加わっています．積をとるということは，2つの特徴が
同時に現れるときに大きな値になります．すなわち，共起の情報が加わったことになります．

このような，非線形変換で線形分離可能な高次元にデータを飛ばしてしまい，マージン最大化基準で
信頼できる識別面を求めるというSVMの方法は非常に強力で，文書分類やバイオインフォマティックス
など様々な分野で利用されています．"
0714,
0715,"そうすると，写像後の空間での識別関数は以下のように書くことができます．

ここで，SVMを適用すると，$\bm{w}$は，式(7.11)のようになるので，以下の
識別関数を得ることになります．

同様に，式(7.12)より，学習の問題も以下の式を最大化するという問題になります．

ここで注意すべきなのは，式(7.20), (7.21)のどちらの式からも$\phi$が消えているということです．
カーネル関数$K$さえ定まれば，
識別面を得ることができるのです．このように，複雑な非線形変換を求めるという操作を避ける方法を
カーネルトリック
とよびます．これがSVMがいろいろな応用に使われてきた理由です．"
0716,"ここまで，数値特徴を対象にSVMを説明してきましたが，SVMは一見カテゴリ特徴の問題に見える自然言語処理でも
多用されている機械学習手法です．
ここでは，典型的なSVMの応用事例として，文書分類問題を取り上げます．

分類対象である文書は文字列データです．この文書という対象の特徴ベクトルをどのように考えればよいでしょうか．
ちょっと驚くかもしれませんが，文書分類では，文書に現れうる全単語をそれぞれの次元に設定します．第$i$次元が
単語$word_i$に対応し，文書に出現すれば1，出現しなければ0とします．
そうすると，特徴ベクトルは数千次元から数万次元になります．

SVMは汎化性能が高いので，このような高次元の識別問題に用いることができます．"
0717,"Grid search は，パラメータの可能な値をリストアップし，そのすべての組み合わせについて性能を評価して最も性能の高い組み合わせを求めます．
図7.3のようなパラメータを組み合わせる空間をグリッドとよびます．

SVMでは，たとえばRBFカーネルの範囲を制御する$\gamma$と，スラック変数の重み$C$は連続値をとるので，手作業でいろいろ試すのは手間がかかります．そこで，グリッドを設定して，一通りの組み合わせで評価実験をおこないます．"
0801,"この章では，数値データからなる特徴ベクトルとその正解クラスの情報からクラスを識別できる，
神経回路網のモデルを作成する方法について説明します．

ニューラルネットワークは，図8.1のような計算ユニットを，階層的に組み合わせて，入力から出力を
計算するメカニズムです．

% figure 8.1

このモデルは生物の神経細胞のモデルであると考えられています．
神経細胞への入力はそれぞれ重み$w$をもっていて，入力があるとそれらの重み付き和が
計算されます．そして，その結果が一定の閾値$\theta$を超えていれば，この神経細胞が出力信号を出し，それが
他の神経細胞へ(こちらも重み付きで)伝播されます．

人間の脳はこのようにモデル化されるニューロンと呼ばれる神経細胞がおよそ$10^{11}$個集まったものです．これらの神経細胞がシナプス結合と呼ばれる方法で互いに結びついていて，この結合が変化することで学習が行われます．"
0802,"前節で述べた誤り訂正学習は，特徴空間上では線形識別面を設定することに相当します．

この識別器を神経細胞のニューロンとみなし，脳の構造に倣って階層状に重ねることで，
非線形識別面が実現できます．図8.3のようにパーセプトロンをノードとして，階層状に
結合したものを多層パーセプトロンあるいは
ニューラルネットワーク
とよびます．

% figure 8.3

脳のニューロンは，一般には図8.3のようなきれいな階層状の結合をしておらず，
階層内の結合，階層を飛ばす結合，入力側に戻る結合が入り乱れていると考えられます．このような
任意の結合を持つニューラルネットワークモデルを考えることもできるのですが，学習が非常に複雑に
なるので，まずは図8.3のような3階層のフィードフォワード型ネットワークを対象とします．
一般に3階層のフィードフォワード型モデルでは，入力層を特徴ベクトルの次元数用意して，それぞれの次元を入力値とし，
出力層を識別対象のクラス数だけ用意します．そして，入力層・出力層の数に応じた適当な数の中間層を用意します．
中間層は隠れ層(hidden layer)とも呼ばれます．"
0803,"前項で説明した基底関数ベクトルによる非線形識別面は，重みパラメータに対しては
線形で，入力を非線形変換することによって実現されています．一方，ここで説明する
ニューラルネットワークによる非線形識別面は，非線形な重みパラメータによって
実現されています．

なぜノードを階層的に組むと非線形識別面が実現できるかというと，図8.4
に示すように，個々のノードの出力であるロジスティック関数を重みを加えて足し合わせることで，
データの境界の形に合わせた識別面を構成することができるからです．"
0804,
0805,"ノードを階層状に組むことによって，複雑な非線形識別面が実現することが可能なことはわかりました．
問題は，その非線形識別面のパラメータをどのようにしてデータから獲得するか，ということです．

もし，入力層から中間層への重みが固定されていると仮定すると，各学習データに対して，各中間層の
値が決まります．それを新たな学習データとみなして，もとのターゲットを教師信号とする
ロジスティック識別器の学習を行えば，中間層から出力層への重みの学習を行うことができます．

しかし，この方法では中間層が出力すべき値がわからないので，入力層から中間層への重みを学習する
ことができません．出力すべき値はわかりませんが，望ましい値との差であれば計算することができます．
出力層では，出力値とターゲットとの差が，望ましい値との差になります．もし，出力層がすべて正しい
値を出していないとすると，その値の算出に寄与した中間層の重みが，出力層の更新量に応じて修正される
べきです．この，重みと出力層の更新量の積が，中間層が出力すべき値との差になります．

このように，出力層の誤差を求めて，その誤差を中間層に伝播させて学習を行う手法(図8.5)を
{\bf 誤差逆伝播法}とよびます．"
0806,"ニューラルネットワークでも，出力と正解情報の二乗誤差$(y_i - o_i)^2$が最小になるように学習を行います．

% align 8.2

ここでは，最急勾配法を用いて重みを学習します．"
0807,誤差の二乗和$E(\bm{w})$の勾配方向の計算は以下のようになります．
0808,"ここで，出力$o_j$を重み$w_i$で偏微分したものは以下の合成微分で求めます．

% equation 8.4

第1項はシグモイド関数の微分です．

% equation 8.5

第2項は入力の重み付き和の微分です．

% equation 8.6

従って，出力層の重みの更新式は以下のようになります．

% equation 8.7

通常，ニューラルネットワークの学習は確率的最急勾配法を用いるので，式8.7の全データに対して和をとる操作を削除します．

また，中間層は，この修正量を重み付きで足し合わせます．"
0809,
0810,"人間の神経回路網は，3 階層のフィードフォワード型ネットワークよりはるかに複
雑な構造をもっているはずです．そこで，誤差逆伝播法による学習が流行した1980 年
代後半にも，ニューラルネットワークの階層を深くして性能を向上させようとする試
みはなされてきました．しかし，多段階に誤差逆伝播法を適用すると，誤差が小さく
なって消失してしまうという問題点があり，深い階層のニューラルネットワークの学
習はうまくはゆきませんでした．しかし，2006 年頃に考案された事前学習法をきっか
けに階層の深いディープニューラルネットワークに関する研究が盛んになり，様々な
成果をあげてきました．



ディープニューラルネットワークは，フィードフォワードネット
ワークの中間層を多層にして，性能を向上させたり，適用可能なタスクを増やそうと
したものです．しかし，誤差逆伝播法による多層ネットワークの学習は，重みの修正
量が層を戻るにつれて小さくなってゆく勾配消失問題に直面し，思うような性能向上
は長い間実現できませんでした．"
0811,"勾配消失問題への別のアプローチとして，ユニットの活性化関数を工夫する方法があります．シグモイド関数ではなく，rectified linear関数とよばれる$f(x)=\max(0,x)$（引数が負のときは0，0以上のときはその値を出力）を活性化関数とした ユニットを，
ReLU
(rectified linear unit)（図8.8）とよびます．

% figure 8.8

ReLuを用いると，半分の領域で勾配が1になるので，誤差が消失しません．また，多くのユニットの出力が0であるスパース（疎ら）なネットワークになる点や，勾配計算が高速に行える点などが，ディープニューラルネットワークの学習に有利に働くので，事前学習なしでも学習が行えることが報告されています．"
0901,"深層学習
は
Deep learning
の訳語で，日本語の文献ではディープラーニングとそのままの単語でよばれることもあります．第1章で述べたように，深層学習は機械学習の一手法で，高い性能を発揮する事例が多いことから，近年，音声認識・画像認識・自然言語処理などの分野で大いに注目を集めています．

本章では，深層学習の基本的な考え方を説明します．

深層学習をごく単純に定義すると，図9.1のような，特徴抽出前の信号を入力をとする
多階層ニューラルネットワークの学習，ということになります．とくに深層学習に用いるニューラルネットワークを
Deep Neural Network (DNN) 
とよびます．

深層学習は，
表現学習(representation learning)とよばれることもあります．
特徴抽出前の生データに近い信号から，その内容を
表現する特徴を学習する，というところがポイントです．"
0902,"これまでに説明してきた識別問題では，何を特徴とするかは既に
与えられたものとしてきました．音声処理や画像処理では，これまでの経験や分析の結果，どのような特徴が識別に役立つか
が分かってきていて，識別問題の学習をおこなう対象は，それらの特徴からなるベクトルで表現されました．一方，深層学習は，どのような特徴を抽出するの
かもデータから機械学習しようとするものです（図9.2）．"
0903,深層学習に用いられるニューラルネットワークは，問題に応じてさまざまな形に特化してゆきました．本章では，その特化した構造を，多階層ニューラルネットワーク，畳み込みネットワーク，リカレントネットワークに分類して説明をします．
0904,
0905,
0906,"多階層ニューラルネットワークは，図9.1のようなニューラルネットワークで，入力に近い側の処理で，特徴抽出をおこなおうとするものです．
これはよく用いられる3階層ニューラルネットワークの入力側に，もう1層の特徴抽出層を付け加えればよい，というもの
ではありません．識別に有効な特徴が入力の線形結合で表される，という保証はないからです．それでは，もう1層加えて
非線形にすればよいかというと，隣接するデータの関連性（音声の場合の時系列のデータの関連性・画像の場合の近接する
空間的なデータの関連性など）
が考慮されていないので，
それでも十分ではないでしょう．つまり，特徴抽出を学習するには十分多くの層を持つニューラルネットワークが必要だという
ことになります．

第8章で説明したニューラルネットワークの学習手法である誤差逆伝播法は多階層構造でもそのまま適用
できます．そうすると，深層学習でも最初からニューラルネットワークを多階層で構成すれば，それで問題が解決するのではないか，と思われるかも
しれません．

しかし，一般に階層が多いニューラルネットワークの学習には問題点があります．
第8章で説明した誤差逆伝播法は，入力層に向かうにつれ修正量が少なくなり，
多階層では入力側の重みはほとんど動かない，
ということがわかっています（図9.3）．

アルゴリズム8.1の修正量$\delta$には$出力値 \times (1-出力値) \quad ただし，0<出力値<1$が掛けられますが，
この値は最大でも$1/4$です．この値を1階層上の修正量の重み付き和にかけるのですが，重みは大きい値を取るノード以外は
小さくなるように学習されます（正則化の議論を思い出してください）ので，この値もそれほど大きくはなりません．
また，学習係数$\eta$を大きくしても値が振動するだけなので，問題の解決にはなりません．3層のfeed forward型では
この修正量の減少はあまり問題になりませんでしたが，階層が4層，5層と増えてゆくと修正量が急激に減ってしまいます．"
0907,"この問題を解決する手法として，事前学習法(pre-training)が考案されました．
誤差逆伝播法を用いた教師あり学習を行う前に，
何らかの方法で重みの初期パラメータを適切なものに事前調整しておくというアイディアです．この事前学習は，入力$\bm{x}$の
情報をなるべく失わないように，入力層側から1層ずつ順に教師なし学習で行います(図9.4)．
入力層から上位に上がるにつれノードの数は減るので，うまく特徴となる情報を抽出しないと情報を保持すること
はできません．このプロセスで，元の情報を保持しつつ，抽象度の高い情報表現を獲得してゆくことを階層を重ねて行うことが
深層学習のアイディアです．"
0908,"深層学習における初期パラメータの調整で必要な，入力の情報をなるべく失わない，より少ないノードへの写像
を学習する手段として，AutoencoderとRestricted Bolzmann Machine(RBM)がよく使われます．ここでは
第8章で説明したフィードフォワード型のニューラルネットワークを用いたAutoencoderに
ついて説明します．

Autoencoderは，図9.5のように，3階層のフィードフォワード型のニューラルネットワークで
自己写像を学習するものです．

自己写像の学習とは，$d$次元の入力${\bf f}$と，同じく$d$次元の出力${\bf y}$の距離（誤差と解釈しても
よいです）の全学習データに
対する総和が最小になるように，ニューラルネットワークの重みを調整することです．

距離は通常，ユークリッド距離が使われます．また，入力が0または1の2値であれば，出力層の
活性化関数としてシグモイド関数が使えるのですが，入力が連続的な値を取るとき，その値を再現するために
出力層では恒等関数を活性化関数として用います．すなわち，中間層の出力の重み付き和をそのまま出力
します．
Autoencoderではこのようにして得られた中間層の値を新たな入力として，1階層上にずらして同様の表現学習を
行います．この手順を積み重ねると，入力に近い側では単純な特徴が，階層が上がってゆくにつれ複雑な特徴が
学習されます．"
0909,
0910,
0911,"ニューラルネットワークの階層を深くすると，それだけパラメータも増えるので，過学習の問題がより深刻になります．そこで，ランダムに一定割合のユニットを消して学習を行う
ドロップアウト
（図9.7）を用いると，過学習が起きにくくなり，汎用性が高まることが報告されています．

ドロップアウトによる学習では，まず各層のユニットを割合$p$でランダムに無効化します．たとえば$p=0.5$とすると，半数のユニットからなるニューラルネットワークができます．そして，このネットワークに対して，ミニバッチ一つ分のデータで誤差逆伝播法による学習を行います．対象とするミニバッチのデータが変わるごとに無効化するユニットを選び直して学習を繰り返します．

学習後，得られたニューラルネットワークを用いて識別を行う際には，重みを$p$倍して計算を行います．これは複数の学習済みネットワークの計算結果を平均化していることになります．

このドロップアウトによって過学習が生じにくくなっている理由は，学習時の自由度を意図的に下げていることにあります．自由度が高いと結合重みが不適切な値（学習データに対しては正解を出力できるが，汎用性がないもの）に落ち着いてしまう可能性が高くなりますが，自由度が低いと，正解を出力するための結合重みの値は特定の値に限定されやすくなります（図9.7）．"
0912,"タスクに特化したディープニューラルネットワークの代表的なものが，画像認識でよく用いられる
畳み込みニューラルネットワーク
(convolutional neural network; CNN)です．CNNは，畳み込み層と，プーリング層を交互に配置し，最後のプーリング層の出力を受ける通常のニューラルネットワークを最終出力側に配置したものです（図9.8）．"
0913,
0914,"畳み込み層の処理は，画像にフィルタをかける処理に相当します（図9.9）．最初の畳み込み層は入力画像と同じ大きさのものを，準備したいフィルタの種類数分だけ用意します．畳み込み層の各ユニットは，入力画像中の一部とのみ結合を持ち，その重みは全ユニットで共有されます．この結合を持つ範囲はフィルタサイズに相当し，この範囲のことを
受容野
とよびます．図9.8では，最初の畳み込み層は3種類のフィルタに相当する処理を行っています．ここでは，それぞれ異なるパターンを学習し，フィルタ係数として獲得しています．

プーリング層は畳み込み層よりも少ないユニットで構成されます．各ユニットは，畳み込み層と同様に受容野を持ち，その範囲の値の平均あるいは最大値を出力とします．これは，受容野内のパターンの位置変化を吸収していることになります．

畳み込みニューラルネットワークでは，特定のユニットは，前の階層の特定の領域の出力だけを受けるという制約を設けているので，単純な全結合のネットワークに比べて，ユニット間の結合数が少なくなります．また，同じ階層のユニット間で重みを共有することで，学習すべきパラメータが大幅に減っていることになります．これらの工夫によって，画像を直接入力とする多階層のニューラルネットワークを構成し，特徴抽出処理も学習の対象とすることができました．このことが，畳み込みニューラルネットワークが各種の画像認識タスクにおいて高い性能を示している原因だと考えられます．"
0915,
0916,"もうひとつのタスクに特化した構造をもつニューラルネットワークとして，
中間層の出力が時間遅れで自分自身に戻ってくる構造をもつ
リカレントニューラルネットワーク
（図9.10(a)）があります．リカレントニューラルネットワーは時系列信号や自然言語などの系列パターンを扱うことができます．

このリカレントニューラルネットワークへの入力は，特徴ベクトルの系列$\bm{x}_1,\bm{x}_2,\dots, \bm{x}_T $という形式になります．たとえば，動画像を入力して異常検知を行ったり，ベクトル化された単語系列を入力して品詞列を出力するようなタスクが具体的に考えられます．これらに共通していることは，単純に各時点の入力からだけでは出力を決めることが難しく，それまでの入力系列の情報が何らかの役に立つという点です．

リカレントニューラルネットワークの中間層は，入力層からの情報に加えて，一つ前の中間層の活性化状態を入力とします．この振舞いを時間方向に展開したものが，図9.10(b)です．時刻$t$における出力は，時刻$t-1$以前のすべての入力を元に計算されるので，これが深い構造をもっていることがわかります．"
0917,"そして，問題となる結合重みの学習ですが，単純な誤差逆伝播法ではやはり勾配消失問題が生じてしまいます．この問題に対する対処法として，リカレントニューラルネットワークでは，中間層のユニットを，記憶構造をもつ特殊なメモリユニットに置き換えるという工夫をします．この方法を，
長・短期記憶
（Long Short-Term Memory; LSTM）とよび，メモリユニットを
LSTMセル
とよびます．LSTMセルは，入力層からの情報と，時間遅れの中間層からの情報を入力として，それぞれの重み付き和に活性化関数をかけて出力を決めるところは通常のユニットと同じです．通常のユニットとの違いは，内部に情報の流れを制御する3つのゲート（入力ゲート・出力ゲート・忘却ゲート）をもつ点です．"
0918,
0919,"これらのゲートの開閉は入力情報を元に判定され，現在の入力が自分に関係があるものか，自分は出力に影響を与えるべきか，これまでの情報を忘れてもよいかが判断されます（もちろん判断基準も学習の対象です）．
学習時には誤差もゲートで制御されるので，必要な誤差のみが伝播することで，勾配消失問題が回避されています．"
1001,"アンサンブル学習とは，識別器を複数組み合わせ，それらの結果を統合することで，個々の識別器よりも性能を向上させる方法です
（図10.1）．ここでの問題設定は識別問題ですが，アンサンブル学習の考え方は，ほぼそのまま回帰問題にも適用できます．

% figure 10.1

アンサンブル学習の説明には，「三人寄れば文殊の知恵」ということわざがよく引き合いに出されます．確かに，一つの識別器を用いて出した結果よりは，多数の識別器が一致した結果のほうが，信用できそうな気はします．

そのような直観的な議論ではなく，本当に多数が出した結論の方が信用できるのかどうかを検討してみましょう，ここで，同じ学習データを用いて，異なる識別器を$L$個の作成したとします．仮定として，識別器の誤り率$\epsilon$はすべて等しく，その誤りは独立であるとします．誤りが独立であるとは，評価用のデータそれぞれに対して，それぞれの識別器が誤る確率が独立であるということで，多くの識別器がいっしょに誤ってしまうようなデータはない，ということです．このような仮定をおくと，この識別器集合に，ある評価用データを与えたとき，識別器が誤る数が$m$個になる確率は二項分布$B(m; \epsilon, L)$となります．"
1002,"具体的な数値で考えるために，識別器の個数$L=11$，誤り率$\epsilon=0.2$として，二項分布$B(m; 0.2, 11)$をグラフにかくと，図
10.2のようになります．

% figure 10.2

識別結果を多数決で決めるとすると，全体として誤った判定をする確率は，6個以上の識別器が誤る確率の総和になります．
これを計算すると約1.2\%ということになります．

個々の識別器は誤り率20\%の性能しかないのに，異なる識別器を11個用意すれば誤り率1.2\%の識別器ができてしまいます．"
1003,"ただし，これは理論上のことで，現実にはこんなにはうまくゆきません．どこが一番現実と合っていないかというと，
識別器の出す誤りが「独立である」というところです．識別対象のデータには，同じクラスのデータとまとまりを形成していて，比較的識別しやすいデータと，境界線付近にあって，識別がしにくいデータがあります（図1.7参照）．識別しにくいデータは，やはり多くの識別器が誤った結果を出してしまうので，多数決をとることによる誤りの減少は見込まれません．

そこで，いかにして独立な識別器を作るかという工夫が，アンサンブル学習においてなされてきました．以下，それらを
説明してゆきます．"
1004,"異なった振る舞いをする識別器を複数作るための最初のアイディアは，異なった学習データを複数用意する，ということです．
ここまでの教師あり学習の説明からもわかるように，学習データが異なれば，たいていその学習結果も異なります．
バギング(Bagging)
はこのアイディアに基づいて，学習データから復元抽出
することで，
もとのデータと同じサイズの独立なデータ集合を作成し，各々のデータ集合に対して同じアルゴリズムで識別器を作成する
ものです（図10.3}）．"
1005,
1006,"復元抽出によって作成されたデータ集合が，もとのデータ集合とどれぐらい異なるのかを試算してみましょう．
データ集合の要素数を$N$とします．もとのデータ集合に含まれる，あるデータが復元抽出後のあるデータ集合に含まれない
確率は，$(1-1/N)^N$です．$N=10$の小さいデータ集合の場合，この確率は$0.349$となり，$N=100$で，$0.366$です．
$N \to \inf$で，この確率は$1/e \fallingdotseq 0.368$となるので，おおよそどのような$N$に対しても，復元抽出後のデータ集合には，もとのデータ集合の約$1/3$のデータが
含まれないことになります．

そして，識別器を作成するアルゴリズムは不安定（学習データの違いに敏感）な方が，少しデータが異なるだけで異なった
識別器になるので，よいといわれています．不安定な識別器としては，枝刈りをしない決定木などがあります．
それぞれの識別器が同じ学習データ量で学習しているので，全ての識別器は同程度に信用できると考え，
結果の統合は単純な多数決とします．"
1007,"バギングでは，不安定な学習アルゴリズムを用いて，異なる識別器を作成しました．しかし，
復元抽出によって作られた個々のデータ集合は，もとの学習データ集合と約$2/3$のデータを共有しているので，とくに，元のデータのまとまりがよい場合，それほど
極端に異なった識別器にはなりません．ここで説明する
ランダムフォレスト(RandomForest)
は，識別器の学習アルゴリズムに，その結果が大きく異なる仕組みを入れる方法です．"
1008,"ランダムフォレストの学習手順は，基本的にバギングアルゴリズムと同様，学習データから
復元抽出して，同サイズのデータ集合を複数作るところから始まります．
次に，各データ集合に対して，識別器として決定木を作成するのですが，ノードでの分岐特徴を
選ぶ際に，全特徴からあらかじめ決められた数

だけ特徴をランダムに選びだし，その中から最も
分類能力の高い特徴（たとえば，式(3.2)で定義したGain値の高いもの）を選びます．
そして，その操作をリーフが単一クラスの集合になるまで再帰的に行います．

図10.4に，ランダムフォレストによる個々の木の作成の様子を示します．
たとえば，学習データの特徴が$\{A,B,C,D,E\}$と5種類あるとして，ルートノードの分岐特徴を決める際は，
ここから予め決められた数（たとえば3種類）をランダムに選択します．ここで，$\{A,B,E\}$が選択された
とすると，それぞれの分類能力を計算し，最も分類能力の高い属性を選んで，その値によってデータを
分割します．分けられたデータ集合に対しても，同様にランダムに属性集合を選択して，その中で最も
分類能力の高い属性を選んで木を成長させます．

% figure 10.4

このような手順で，識別器の方を強制的に異なったものにするのがランダムフォレストの手法です．"
1009,"通常の決定木の
学習は，リーフのデータ数が一定値以下になるとそれ以上の成長を止めるか，十分に伸ばした後に
枝刈りをするかして，過学習をしないように工夫します．しかし，ランダムフォレストでは
意図的に過学習をさせ，できるだけ異なった木を作るようにします．"
1010,"バギングやランダムフォレストでは，用いるデータ集合を変えたり，識別器を構成する条件を変えたりすることによって，異なる識別器を作ろうとしていました．これに対して，
ブースティング (Boosting) 
では，誤りを減らすことに特化した識別器を，次々に加えてゆくという方法で，異なる振る舞いをする識別器の集合を作ります．"
1011,
1012,"作成する識別器に対して，誤りを減らすことに特化させるために，個々のデータに対して重みを設定します．バギングではすべてのデータの重みは平等でした．
一方，ブースティングのアイディアは，
各データに重みを付け，そのもとで識別器を作成します．
最初は，平等な重みが付いた学習データによって識別器を作成し，その識別器によって誤識別されたデータに対して，その重みを増やします．そのように重みが変更されたデータ集合に対して，次の識別器を学習するというやりかたで，異なる識別器を逐次的に作成してゆきます．後から作られる
識別器は，前段の識別器が誤ったデータを優先的に識別するようになるので，前段の識別器とは異なり，かつその弱いところを補うような相補的働きをします（図10.5）．

% figure 10.5

ブースティングに用いる識別器の学習アルゴリズムは，基本的にはデータの重みを識別器作成の
基準として取り入れている必要があります．ただし，学習アルゴリズムが重みに対応していない場合は，
重みに比例した数を復元抽出してデータ集合を作ることで対応可能です．

このように，前段での誤りに特化して逐次的に作成された識別器は，もとの学習データをゆがめて作成されているので，未知の入力に対しては，もとの学習データに忠実に作られた識別器（たとえば，図10.5の識別器1）とは，信頼性が異なります．したがって，バギングのように単純な多数決で
結論を出すわけにはゆきません．各識別器に対してその識別性能を測定し，その値を重みとする重み付き投票
で識別結果を出します．"
1013,"このようなブースティングアルゴリズムの代表的なものに
AdaBoost
があります．
AdaBoostでは，誤識別されたデータの重みの和と，正しく識別されたデータの重みの和とが等しくなるように，
各データの重みの変更が行われます．学習ステップにおける$t$段階目の識別器の誤り率を$\epsilon_t$とすると，
誤識別されたデータの重みに$\frac{1}{2\epsilon_t}$，正しく識別されたデータの重みに$\frac{1}{2(1-\epsilon_t)}$を
掛ければ，それぞれのデータの割合が$\epsilon_t:1-\epsilon_t$であることから，更新後のそれぞれの重みの総和が
$\frac{1}{2}$になることがわかります．なお，この重みの更新は，誤識別されたデータの重みが大きくなるように
更新されなければ意味がないので，更新中に$\epsilon_t \ge 0.5$になると繰り返しが中断されます．"
1014,"前章で，Adaboostは，特定の損失関数を最小化していることと同じであることを説明しました．Adaboostは，比較的素朴な方法で識別器の逐次的組み合わせをおこなった結果，それが理論的に損失関数最小化の枠組みに当てはまるというものでしたが，結局，損失関数最小化をおこなっているのであれば，直接その損失関数が最も減るような識別器を加えることを逐次的におこなうことで，よりよい性能が実現できそうです．

そのようなアイディアでブースティングをおこなっているのが，
勾配ブースティング
です．以下，勾配ブースティングの考え方を説明します．

ブースティングでは，全体の識別器の出力は，式(10.2)に示すように，M個の識別器$h_m$の重み付き和で得られます．

% equation 10.2

この形式で，ブースティングにおける逐次加法的な学習プロセスを表現すると，
式(10.3)のようになります．

% equation 10.3

学習の各ステップで，新たに加える識別器$h_m(\bm{x})$を選択するために，損失関数$L$を導入し，その値が最小となるものを選ぶこととします．

% equation 10.4"
1015,"式(10.4)で，差が最小になるものを求めている部分を，損失関数の勾配に置き換えた式(10.5)に従って，新しい識別器を構成する方法が，勾配ブースティングです．

% equation 10.5

損失関数としては，二乗誤差，誤差の絶対値，フーバー損失（$|x| \leq \epsilon$ の範囲で2次関数，その外側の範囲で線形に増加）などが用いられます．"
1101,"ここからは，教師なし学習の問題に取り組みます．
この章では，特徴ベクトルの要素が数値である場合に，その特徴ベクトルが生じるもとになった
クラスを推定するモデル推定の問題を扱います(図11.1)．"
1102,"教師なし学習とは，正解情報が付けられていないデータを対象に行う学習です．
データの集合を，以下のように定義します．

この章では，この特徴ベクトルの要素がすべて数値である場合を考えます．
要素がすべて数値であるということは，特徴ベクトルを$d$次元空間上の点として考えることができます．
そうすると，モデル推定は，特徴空間上にあるデータのまとまりを見つける問題ということになります．データがまとまっている，
ということは，共通の性質をもつようにみえる，ということなので，図11.2のように，このような個々のデータを生じさせた共通の性質を持つクラスを見つけることが目標になります．"
1103,"与えられたデータをまとまりに分ける操作を，クラスタリングといいます．「まとまりに分ける」という部分を
もう少し正確にいうと，

分類対象の集合を，内的結合と外的分離が達成されるような部分集合に分割すること

になります．つまり，一つのまとまりと認められるデータは相互の距離がなるべく近くなるように（内的結合），
一方で，異なったまとまり間の距離はなるべく遠くなるように（外的分離），データを分けるということです．

このようなデータの分割は，個々のデータをボトムアップ的にまとめてゆくことによってクラスタを作る
階層的手法と，全体のデータの散らばり（トップダウン的情報）から最適な分割を求めてゆく
分割最適化手法とに分類できます．"
1104,"階層的手法の代表的手法である
階層的クラスタリング
は，近くのデータをまとめて小さいクラスタを作り，その小さいクラスタに近くのデータを取り込むか，あるいは小さいクラスタ同士をまとめて，少し大きめの新しいクラスタを作るという手順を繰り返すものです（図11.3）．

アルゴリズムとしては，一つのデータからなるクラスタをデータ個数分作成するところから始まって，最も近いクラスタを融合して新しい
クラスタを作る操作を繰り返し，最終的にデータが一つのクラスタになれば終了です．
図11.4のように，データまたはクラスタを融合
する操作を木構造で記録しておけば，全データ数$N$から始まって，1回の操作で
クラスタが一つずつ減ってゆき，最後は一つになるので，任意のクラスタ数からなる結果を得ることができます．"
1105,階層的クラスタリングの手順を，アルゴリズム11.1に示します．ここで，simはクラスタ間の類似度を計算する関数です．
1106,"ここで，クラスタ間の類似度計算に関して，いくつか異なる計算方法があり，そのいずれを採用するかによって，
出来上がるクラスタの性質に違いが生じます．

\begin{itemize}
\item 単連結法(SINGLE)\\
最も近い事例対の距離を類似度とする．クラスタが一方向に伸びやすくなる傾向がある．
\item 完全連結法(COMPLETE)\\
最も遠い事例対の距離を類似度とする．クラスタが一方向に伸びるのを避ける傾向がある．
\item 重心法(CENTROID)\\
クラスタの重心間の距離を類似度とする．クラスタの伸び方型は単連結と完全連結の間をとったようになる．
\item Ward法(WARD)\\
与えられたクラスタを融合したときのクラスタ内のデータと，クラスタ中心との距離の二乗和を求め，そこか各クラスタについて同様に求めた値を引いたものを類似度とする．比較的良い結果が得られることが多いので，階層的クラスタリングでよく用いられる類似度基準である．
\end{itemize}"
1107,"階層的クラスタリングはボトムアップ的にデータをまとめるので，全体的な視点からみると，いびつなクラスタを
形成してしまうことがあります．一方，全体的な視点でまとまりのよいクラスタを求める手順が，
分割最適化クラスタリングです．

分割最適化クラスタリングでは，データ分割のよさを評価する関数を定め，その評価関数の値を最適化することを
目的とします．ところが，データ数を$N$とすると，データを分割する場合の数は，$N$に対して指数的（例えば二つのクラスタに
分ける場合なら$2^N$）になるので，$N$がちょっと大きな数になると，すべての可能な分割の評価値を求めるのは
実質的に不可能になります．

このような場合の常套手段として，探索によって準最適解を求めるということを考えます．"
1108,"分割最適化クラスタリングの代表的手法である
k-meansクラスタリング (k-平均法)
では，クラスタ数$k$をあらかじめ与え，各クラスタの平均ベクトルを乱数で生成し（あるいはランダムに$k$個データを選んで平均ベクトルとし），各データを
最も近い平均ベクトルを持つクラスタに所属させた後，それぞれのクラスタの平均ベクトルを，その所属するデータから再計算します．この手順を，全クラスタの平均ベクトルが動かなくなるまで繰り返します
（図11.6）．"
1109,"ここで，データ分割のよさを評価する関数を，各データと所属するクラスタの中心ベクトルとの距離の総和と定義すると，クラスタ中心の位置更新によって
評価関数の値が増えることはありません．したがって，この手順によって局所的最適解にたどり着くことが
できます．わざわざ「局所的」といっているということは，全体としての最適解であるかどうかは，この手順ではわからない
ということです．したがって，k-means法でクラスタリングをおこなう際は，異なった初期値で複数回おこない，評価値（たとえば，上記の距離の総和）の
もっともよいものを結果として採用することになります．"
1110,"k-Meansアルゴリズムにおける，事前にクラスタ数$k$を固定しなければいけないという問題点を回避する手法として，
クラスタ数を適応的に決定する方法が考えられます．最初は2分割から始まって，得られたクラスタに対して分割が適当
でないと判断されるまで，k-means法によるクラスタリングを繰り返すというもので，この方法を
X-meansアルゴリズム
とよびます．

このアルゴリズムの勘所は，さらなる分割が適当であるかどうかの判断k基準として，
分割前後でモデルのよさを定量的に表したBIC (Bayesian information criterion) 値を比べるという点です．

BICは以下の式で得られる値です．

ただし，$\log L$はモデルの対数尤度（各クラスタの正規分布を所属するデータから最尤推定し，その分布から各データが出現する確率の対数値を得て，それを全データについて足し合わせたもの）$q$はモデルのパラメータ数（クラスタ数に比例），$N$はデータ数です．BICは小さいほど，得られた
クラスタリング結果がデータをよく説明しており，かつ詳細になりすぎていない，ということを表します．

モデルを詳細にすればするほど（クラスタリングの場合はクラスタ数を増やせば増やすほど），対数尤度を大きくする
ことができます．極端な場合，1クラスタに1データとすると，そのクラスタの正規分布の平均値がそのデータになるので，
その分布の最も大きい値をとる（BICを小さくする方向に寄与する）ことになります．しかし，その場合，$q$の値が大きくなるので，BIC全体としては大きな値となってしまい，対数尤度とクラスタ数のバランスが取れたものが選ばれるという仕組みになっています．

クラスを表すモデルのよさを定量的に表現する基準はひとつではありませんが，ここで示したBICや，同様の目的で使われるAIC(Akaike information criterion)は，モデルの対数尤度とパラメータの複雑さのバランスを取った式で，その評価値を表していることから，さまざまなモデル選択の状況で用いられています．"
1111,"教師なし学習の実用的な応用例として，異常検出があります．
異常検出の問題設定は，入力$\{\bm{x}_i\}$に含まれる異常値を，教師信号なしで見つけることです．
ここでは，最も基礎的な異常検出として，外れ値の検出について説明します．

外れ値は，学習データに
含まれるデータの中で，ほかと大きく異なるデータを指します．たとえば，全体的なデータのまとまりから極端に離れた
データや，教師ありデータの中で，一つだけほかのクラスのデータに紛れ込んでしまっているようなデータです．
これらは，計測誤りや，教師信号付与作業上でのミスが原因で生じたと考えられ，学習をおこなう前に
除去しておくのが望ましいデータです．"
1112,"ここで紹介する
局所異常因子 (LOF: Local Outlier Factor)の考え方は，
単純にいうと，近くにデータがないか，あるは極端に少ないものを外れ値とみなす，というものです．
ただし，この「近く」という概念は，データの散らばり具合によって異なるので，一定の閾値をあらかじめ定めておくことはできません．
そこで，それぞれのデータにとっての「周辺」を，$k$番目までに近いデータがある範囲と定義し，周辺にあるデータまでの距離の平均を，「周辺密度」として定義します（図11.13）．

そして，あるデータの周辺密度が，近くの$k$個のデータの周辺密度の平均と比べて極端に低い
ときに，そのデータを外れ値とみなします．"
1113,"まず，データの個数に応じて$k$を適当な値に定めます．その$k$を用いて，あるデータ$\bm{x}$から，別のデータ$\bm{x}'$への
到達可能距離(reachability distance)を式(11.3)のように定義します．

ここで，$\bm{x}^{(k)}$は，$\bm{x}$に$k$番目に近いデータです．式(11.3)で求まる値は，
$\bm{x}$と$\bm{x}'$が十分に遠ければ，通常の距離です．一方，$\bm{x}'$が$\bm{x}^{(k)}$よりも$\bm{x}$に近ければ，
$|| \bm{x}-\bm{x}^{(k)} ||$に補正されます．

次に，この到達可能距離を用いて，$\bm{x}$の周辺密度を定義します．式(11.4)で定義される量を，
局所到達可能密度 (local reachability density)
とよびます．

$LRD_k(\bm{x})$は，$\bm{x}$から$k$番目までに近いデータとの到達可能距離の平均を求め，その逆数をとったものです．
$k$番目までのデータが近くにあるとき，到達可能距離の平均は小さい値になるので，その逆数である
局所到達可能密度は大きい値になります．

ここで，到達可能距離ではなくなぜ単純に距離を用いないのか，という疑問が出るかもしれません．
これは，単純な距離を用いると$\bm{x}$のごく近い距離にデータがあるときに，その逆数はとても
大きな値になってしまって，安定的な計算ができなくなる可能性があるからです．

そして，この局所到達可能密度を用いて，式(11.4)のように$\bm{x}$の
局所異常因子 $LOF$
を定義します．

$LOF_k(\bm{x})$は，$\bm{x})$に対して$k$番目までに近いデータの局所到達可能密度の平均と，
$\bm{x})$の局所到達可能密度の比です．
$k$番目までに近いデータの局所到達可能密度の平均値に比べて，$\bm{x}$の局所到達可能密度の
値が極端に低い場合，$LOF_k(\bm{x})$は大きな値をとって，$\bm{x}$が外れ値であることを示唆します．
一方，これらの値に大きな違いがないとき，$LOF_k(\bm{x})$は1に近い値となって，
$\bm{x}$が正常なデータであることを示します．

異常検出は，外れ値の検出を応用してセンサー入力から機械の故障を予知したり，
イベント系列特徴を入力して，クレジットカードの不正使用を検出したりする応用が考えられています．"
1114,"ここでは，ここまでに説明してきたクラスタリングの結果を用いて，新たなデータが観測されたときに
そのデータが属するクラスタを決める，という問題を考えます．つまり，教師なし学習で
識別器を作りたい，ということと同じです．

k-meansアルゴリズムの結果は，各クラスタの平均ベクトルなので，新しく観測した
データと，各クラスタの平均ベクトルとの距離を求めて，最も近いクラスタに分類する
という手法は，簡単に思いつきます．しかしこの距離計算は，全クラスタの分散が等しい
ことを前提にしており，クラスタ毎にデータの広がり方が異なる場合は，
適切な結果になりません．また，クラスタの事前確率も考慮されていません．

第4章で説明したように，事後確率最大となる識別結果は，
事前確率と尤度（各クラス毎の確率密度関数が観測されたデータを生成する確率）の積を
最大とするクラスとなるので，よい識別器を作るためにはこれらの確率が必要です．

事前確率はクラスタリング結果のデータ数の分布から求まります．そこで，
尤度を計算するための確率モデルを，与えられた教師なし学習データから
求めるという問題設定で，その解決法を考えてゆきましょう．

k-means法を代表とする分割最適化クラスタリングは，平均値のみを推定していたので，
この考え方を一般化します．各クラスタの確率分布の形を仮定して，そのパラメータを学習データから推定する
という問題を設定します．確率分布として式(11.6)のような正規分布（ガウス分布）を仮定すると，教師なし学習データから，クラスタ$c_m$の平均$\bm{\mu}_m$と分散$\bm{\mu}_m$を推定する問題になります．

k-means法では，各データはいずれかのクラスタに属していました．一方，
この方法の場合は，どの$\bm{x}$に対しても，すべてのクラスタが式(11.6)に基づいて，そのデータがそのクラスタから生成された確率を出力します．すなわち，
個々のデータはどのクラスタに属するかを一意に決めることができず，クラスタ1に属する確率が
0.2，クラスタ2に属する確率が0.8，といった表し方になります（図11.16）．このような表現を
混合分布
による表現といいます．"
1115,"このような設定で，k-meansアルゴリズを一般化すると，以下のように考えることができます．

\begin{itemize}
\item $k$個の平均ベクトルを乱数で決める\\
 $\Rightarrow$ $k$個の正規分布を乱数で決める
\item 平均ベクトルとの距離を基準に，各データをいずれかのクラスタに所属させる\\
 $\Rightarrow$ 各分布が各データを生成する確率を計算し，それを帰属度として，各クラスタにゆるやかに所属させる
\item 所属するデータをもとに平均ベクトを再計算する\\
 $\Rightarrow$ 各データの帰属度をデータの重みとみなして，各分布のパラメータを再計算する
\end{itemize}

たとえば，クラスタ1に属する確率が0.2であるデータは，クラスタ1の平均ベクトルの再計算の時には0.2個分として計算することになります．
分散の計算に関しても同様です．"
1116,"このように，ある時点での分布を使って各データがそのクラスタに属する確率を求め，その確率をデータの重みとみなして分布のパラメータの再計算を行うアルゴリズムを
EM アルゴリズム(Expectation-Maximization)
とよびます．"
1201,"パターンマイニングはデータマイニングともよばれ，ビッグデータ活用の一つとして注目を集めているものです．
パターンマイニングの応用例としては，ネットショッピングサイトなどでの「おすすめ商品」の提示

や，データからの連想規則（あるいは相関規則）の抽出による新たな知見の獲得などが試みられています．

この章では，まず，パターンマイニングの基本的な手法であるApriori（アプリオリ）アルゴリズムとその高速化版であるFP-Growthについて説明します．次に，問題設定を推薦システムに絞り，協調フィルタリングとMatrix Factorizationについて概説します．


この章で扱う問題は，カテゴリからなる特徴ベクトルに対して，正解が付与されていない状況（すなわち「教師なし」の状況）で，そのデータに潜んでいる有用なパターンを見つけてくる，というものです（図12.1）．一般にパターンマイニングとよばれます．

% figure 12.1

パターンマイニングの基本技術は
頻出項目抽出
です．これは，データ集合中に一定頻度以上で現れるパターンを抽出する手法です．この頻出項目から，
連想規則抽出
をおこなうことができます．"
1202,"また，この章で扱うカテゴリ特徴は，あるユーザがある商品を「購入した」／「購入しなかった」のような2値に縮約させて扱うことが可能なことが多いので，これらを数値1, 0と置き換えると，学習データ全体を，値がまばらに入っている巨大な行列とみなすことができます．この行列に対して，次元削減手法を適用して，役に立つ情報を抽出することも，パターンマイニングの一部として扱います．"
1203,"パターンマイニングで扱うデータは，一般的には\ruby{疎}{まばら}なデータです．典型的なものはスーパーマーケットの売上記録で，
そのスーパーで扱っている商品点数が特徴ベクトルの次元数となり，各次元の値はその商品が買われたかどうかを記録したものとします．
そうすると，各データは一回の買い物で同時に買われたものの集合になります．この一回分の記録をトランザクションとよびます．
スーパーで揃えている商品の種類数（こちらは数千から数万）に比べて，一回の買い物で客が買う商品の種類数（こちらはせいぜい数十）は桁違いに少ないので，各トランザクションでは特徴ベクトルのほとんどの次元の値が空白で，ごく小数の次元のデータが埋まっている状況になります．このようなデータを疎なデータとよびます．

イメージしやすいようにごく小さな例を示しましょう．商品点数が$\{ミルク, パン, バター, 雑誌\}$の4点，トランザクションが6件の
データを表12.1に示します．
ここで，t は各トランザクションにおいて，その商品が買われたことを意味します．以下，商品を項目とよびます．

% table 12.1

ざっと見たところ，パンを買った人が多いようです．また，ミルクとパンが一緒に売れることも多いようです．
「多いようだ」「少ないようだ」という定性的な判断ではなく，定量的な基準を決めて，その基準を超えるパターンを
見つけましょう．

データ中によく現れるということは，「全データに対して，ある項目集合が出現する割合が一定以上である」と解釈します．
これを
支持度 (support)
とよび，式(12.1)で計算します．ただし，$T$は全トランザクション件数，
$T_{\mbox{items}}$は項目集合 items が出現するトランザクション件数です．

% equation 12.1

表12.1の項目集合$\{ミルク, パン\}$の支持度は，$\mbox{support}(\{ミルク, パン\})= 3/6 =0.5$となります．"
1204,"ここでやっていることは，項目集合を作って数えれば終わりなので，あまり難しいことをしているようには見えません．
ところが，この「項目集合を作って」というところが厄介なのです．実際のスーパーマーケットの売上記録を対象として
特徴ベクトルを構成すると，数千次元を超えるものになります．低く見積もって1,000種類の商品点数だとしても，
可能な項目集合の数は$2^{1000}-1$となります．
これは，まともにすべての可能な組合せに
ついて計算することは難しい状況です．

したがって，重要なことは，支持度を計算する項目集合をいかにして絞り込むか，ということになります．"
1205,"ここでもう一度，表12.1の小規模データに戻って，項目集合を絞り込む方法を考えましょう．今度は図示しやすいように，
項目に通し番号を付けて，$\{0,1,2,3\}$と表します．すべての可能な項目の組合せは$2^4-1=15$で，図12.2に丸で示すもの（ただし，最上段の空集合$\emptyset$は除く）になります．

% figure 12.2

ここで，a prioriな原理
として，

ある項目集合が頻出ならば，その部分集合も頻出である

を考えます．
そうすると，上で述べたa prioriな原理から，

ある項目集合が頻出でないならば，その項目集合を含む集合も頻出でない

が成り立ちます．"
1206,"これは，命題論理でいうところの ""AならばB"" という形をしています．
命題論理では，""AならばB"" が成り立つならば（真ならば），その対偶である ""BでないならばAでない"" も必ず
成り立ちます．"
1207,"図で表すと，図12.3のようになります．

% figure 12.3

この a priori な原理の対偶を用いて，小さな項目集合から支持度の計算を始め，項目集合を大きくしてゆく際に，頻出でない項目集合をそれ以上拡張しないことで，調べるべき項目集合を減らす方法が，
Aprioriアルゴリズム
です．"
1208,アルゴリズム12.1 に，Aprioriアルゴリズムの手順を示します．ここで，$F_k$は要素数$k$の頻出項目集合，$C_k$は$F_{k-1}$の要素を組み合わせて作られる頻出項目集合の候補です．また，あらかじめ抽出する項目集合の支持度の閾値を決めておき，それを超えるものを頻出項目集合とします．
1209,"この節では，教師あり／教師なしのそれぞれのデータから規則を学習する方法を考えてみます．規則の学習では，学習データが教師ありか教師なしかで，問題設定や学習アルゴリズムが異なります．
教師ありデータからの規則の学習では，結論部はclass特徴と決まっていました．
今から考える教師なしデータの場合，どの特徴（あるいはその組合せ）が結論部になるのかはわかりません．
むしろ，結果として得られた規則のそれぞれが，異なった条件部・結論部をもつことが多くなります．たとえば，「商品Aを購入
したならば，商品Bを購入することが多い」，「商品Cを購入したならば，商品Dと商品Eを購入することが多い」といった
規則になります．
まず，規則の有用性をどのようにして評価するか，ということです．ここでは，確信度(confidence)とLift値を紹介します．

確信度は，規則の条件部が起こったときに結論部が起こる割合を表し，式(12.3)で計算します．この割合が高いほど，この規則にあてはまる事例が多いと見なすことができます．

% align 12.3

リフト値は，規則の結論部だけが単独で起こる割合と，
条件部が起こったときに結論部が起こる割合との比を表し，式(12.4)で計算します．この値が高いほど，得られる情報の多い規則であることを表しています．"
1210,
1211,"このような規則を作るために，まずAprioriアルゴリズムで頻出項目を抽出します．次に，その頻出項目の要素を，条件部と結論部に分けて可能な規則集合を生成
します．そして，その規則の有用性を評価し，役に立ちそうなものだけに絞り込みます．"
1212,"ここでも a priori原理に基づき，評価値の高い規則を絞り込むことを試みます．以下，評価値を確信度とした場合について説明します．

ここでの原理は，

「ある項目集合を結論とする規則の確信度が高ければ，その部分集合を結論とする規則の確信度も高い」

を考えます．

これは
「商品Aを購入したならば，商品Bと商品Cを購入する」という規則の確信度が高ければ，
「商品Aを購入したならば，商品Bを購入する」という規則の確信度も高い，という当たり前のことです．

その対偶は

「ある項目集合を結論とする規則の確信度が低ければ，その項目集合を含む項目集合を結論とする規則の確信度も低い」

となります．少しややこしいですが，図で表すと，図12.6のようになります．"
1213,
1214,"前節で説明したAprioriアルゴリズムの問題点として，やはり計算量が膨大であることが挙げられます．
一般にパターンマイニングの対象であるトランザクションデータは膨大で，アルゴリズム中に
(候補数)×(トランザクション数) のループがあるので，この部分をなんとか減らさなければ高速化はできません．

そこで，高速化のアイディアとして，トランザクションデータをコンパクトな情報に変換し，そのコンパクトな情報に対して
パターンマイニングを行うという手法が考えられました．この手法を
FP-Growthアルゴリズム
とよびます．

トランザクションデータをコンパクトにする手段として，まず特徴を出現頻度順に並べ替えます．そして頻度の高い特徴から
順にその情報をまとめると，「商品Aの購入が100件，そのうち商品Bも同時に購入が40件，商品Cも同時に購入が30件，...」のように
多数のトランザクションの情報を手短に表現できます．ただし，このような自然言語による表現はプログラムによる処理に
向かないので，この情報を木構造で保持します．

ここまでの手順を，例を用いて説明します．まず，以下のようなトランザクション集合を学習データとします．
ここで出現する文字は特徴名で，出現しているときはその値がtとなっているものとします．

% center

次に，特徴をその出現頻度順にソートし，出現頻度が低い特徴（ここでは2回以下しか現れないもの）をフィルタにかけて消去します．
出現頻度が低い特徴は，Aprioriアルゴリズムでの頻出項目抽出や連想規則抽出でも，余計な候補を生成しないために最初に除かれて
いました．

ソート，フィルタリング後の結果は以下のようになります．"
1215,"そして，このデータから
FP-木 (Frequent Pattern Tree) 
を作成します．

FP-木は，最初にnullというカテゴリを付けた根ノード（ルート）を用意し，トランザクションを順にその木に挿入してゆきます．
挿入アルゴリズムは以下のようになります．

% algorithm 12.4

具体的な FP-木の作成手順は図12.7のようになります．まず，$\{z,r\}$がnull($\emptyset$)を根とする
FP-木に挿入されます．次に，$\{z,x,y,s,t\}$の挿入です．まず$z$はFP-木にあるのでカウントを
1増やして2として，この$z:2$をルートとするFP-木に対して，残りの$\{x,y,s,t\}$を挿入します．
次の$x$はFP-木にないので，新たにノードを作って$z:2$につなぎます．そして，この新しい$x:1$をルートとするFP-木
に対して残りの要素を挿入する作業を再帰的に繰り返します．

% figure 12.7

できあがったFP-木に対して，特徴を見出しとするヘッダテーブルを作成し，その頻度を記録しておくとともに
FP-木に出現する同じ要素をリンクで結んでおきます（図12.8上）．特定の特徴は，自分より頻度の高い特徴の出現の有無に
応じて，複数の枝に分かれて出現します．このリンクをたどって集めた出現数は，全体のトランザクション集合での
出現数に一致します．

% figure 12.8"
1216,"パターンマイニングは作成したFP-木を対象に行います（図12.8下）．たとえば，頻出項目抽出で$\{x,r\}$の頻度を求めたいときは，
まずヘッダテーブルを引いて頻度の少ない方を選びます．ここでは$r$が3回，$x$が4回なので，$r$のリンクをたどりながら
頻度計算を行います．ヘッダテーブルからスタートして，最初の$r$から親を辿り，$x$が見つからないので，
このパスでは$\{x,r\}$が共起していない，ということになります．次の$r$のリンクをたどり，その親をたどると，
今度は$x$が見つかりました．その場合は，$r$の頻度をカウントに加えます．同様に最後まで$r$のリンクをたどってゆき，
親に$x$が出現するパスにある$r$の頻度を足してゆくと，最後は$\{x,r\}$の頻度になります．"
1217,前節までで扱ったトランザクションデータは，それぞれのデータが1件分の売り上げを表していました．このデータを個人に対応づけてまとめると，どの個人がどの商品を購入しているのかがわかるデータになります．本節では，このようなデータを対象に，個人に対して推薦をおこなうシステムの構築をテーマに，そのための機械学習手法を説明してゆきます．
1218,
1219,"協調フィルタリング
の前提は，どの個人がどの商品を購入したかが記録されているデータがあることです．そして，新規ユーザが，ある商品を購入したときに，記録済みのデータと購入パターンが似ているデータを探して，検索結果のユーザが購入していて，かつ新規ユーザが購入していない商品を推薦するというのが，基本的な考え方です．

しかし，この個人別の購入データは，前節までのトランザクションデータとどうように，まばらに値が入っているデータです．購入パターンが似ているユーザを探す際に，データをベクトルとみなして，コサイン類似度による計算をおこなっても，ほとんど一致する項目数を数えているに過ぎないような状況になってしまいます．


そこで，購入データをもっと低次元の行列に分解し，ユーザ・商品の特徴を低次元のベクトルで抽出する方法が考えられました．"
1220,"Matrix Factorizationは，まばらなデータを低次元行列の積に分解する方法の一つです．一般に，行列分解にはSVD (Singular Value Decomposition) とよばれる方法がありますが，推薦システムにこの方法を適用しても，うまくいかないことが多いといわれています．その理由として，購入データに値が入っていないところは，「購入しない」と判断したものはごく少数で，大半は，「検討しなかった」ということに対応するからです．購入したものを1，しなかったものを0として行列で表現した購入データをそのまま推薦に利用すると，1が「好き」，0が「きらい」に対応するものとして扱ってしまいます．

そのようなことを避けるために，値の入っているところのみで最適化をおこなう手法が，
Matrix Factorizationです．"
1301,"この章では，もう一度教師あり学習の設定に戻って，系列データを識別する手法について説明します．系列データとは，個々の要素の間に i.i.d. の関係が成立しないものです．
系列データの識別をおこなうモデルを学習するためには，一部教師なし学習の要素が入ってくる場合があるので，
この順序で説明することとしました．

入力の系列長と出力の系列長との関係を整理すると，系列データの識別問題は，以下の三つのパターンに分類されます．

\begin{enumerate}
\item 入力の系列長と出力の系列長が等しい問題
\item 入力の系列長にかかわらず，出力の系列長が1である問題
\item 入力の系列長と出力の系列長の間に，明確な対応関係がない問題
\end{enumerate}

1.は，単語列を入力して，名詞や動詞などの品詞の列を出力する，いわゆる形態素解析処理が典型的な問題です．一つの入力（単語）に一つの出力（品詞）が対応します．この問題の最も単純な解決法としては，これまでに学んだ識別器を入力に対して逐次適用してゆくというものが考えられます．しかし，ある時点の出力がその前後の出力や，近辺の入力に依存している場合があるので，そのような情報をうまく使うことができれば，識別率を上げることができるかもしれません．この問題が本章の主題の一つである系列ラベリング問題です．

2.は，ひとまとまりの系列データを特定のクラスに識別する問題です．たとえば動画像の分類や音声で入力された単語の識別などの問題が考えられます．最も単純には，入力をすべて並べて一つの大きなベクトルにしてしまうという方法が考えられますが，入力系列は一般に時系列信号でその長さは不定なので，そう簡単にはゆきません．また，典型的には入力系列は共通の性質を持ついくつかのセグメントに分割して扱われますが，入力系列のどこにそのセグメントの切れ目があるかという情報は，一般には得られません．そこで，このセグメントの区切りを隠れ変数の値として，その分布を教師なしで学習するという手法と，通常の教師あり学習を組み合わせることになります．これが系列認識問題です．

3.は連続音声認識が典型的な例で，早口かゆっくりかによって単位時間当たりの出力単語数が異なります．
この問題は学習にも認識にも相当込み入った工夫が必要になるので，本章ではその概要のみ説明します．音声認識の詳細に関しては，拙著\cite{araki15}をご覧ください．"
1302,"最初の問題設定として，ラベル特徴の系列を入力として，それと同じ長さのラベル系列を出力する識別問題を扱います．
では，このような系列ラベリング問題を，機械学習によって解決する識別器の構成を考えてゆきましょう．

単純に一つの入力に対して一つのラベルを出力する識別器を順次適用するという方法では，系列としての性質を捨ててしまっているという問題点があります．学習データは，入力系列と出力ラベルのペアとして与えられますが，形態素解析や固有表現抽出の例でみたように，出力系列には並びによる依存関係があるので，個々の識別問題として扱うのは不適当だということです（問題点1）．

それでは出力もまとめてしまって，出力系列を一つのクラスとするということも考えられますが，通常，
そのクラス数は膨大な数になってしまいます．たとえば，品詞が10種類で，20単語からなる文にラベル付けする問題で
は$10^{20}$種類の出力が可能になり，これらを個別のクラスとして扱うのはほとんど不可能です（問題点2）．"
1303,"前節で典型的な例としてあげた形態素解析は，単語の系列を入力として，それぞれの単語に品詞を付けるという問題です
(図13.1)．
形態素の列はある言語の文を構成するので，その言語の文法に従った並び方が要求されます．たとえば，日本語の形態素列は，形容詞の後には名詞がくることが多い，助詞の前には名詞がくることが多いなどの傾向が，明らかに存在します．

また，地名・人名・組織名・日時などの特定の表現を文中から特定の表現を抜き出す
固有表現抽出
（チャンキングとも呼びます）も，系列ラベリングの典型的な問題です．
1単語が1表現になっていれば形態素解析と同じ問題ですが，複数の単語で一つの表現になっている場合があるので，
その並びにラベルを付けます．ラベルの付け方は，その表現の開始を表すB (Beginning)，2単語目以降の表現の構成要素を指す
I (Inside)，表現外の単語を表すO (Outside)の3種類になります．これは，Iの前は必ずBかIであることや，BやIの連続出現数に
それぞれおおよその上限数があることなど，出力の並びに一定の制約があります．このラベル方式にはIOB2タグという名前がついています．

たとえば，文中から「人を指す表現」を抽出した結果は，図13.2のようになります．"
1304,そこで，利用できる素性を図13.3に示す組合せに限定します．つまり，出力系列で参照できる情報は一つ前のみ，入力系列は自由な範囲で参照できるとします．出力系列を参照する素性を遷移素性，入力と対応させる素性を観測素性と呼びます．
1305,"前後の入力や一つ前の出力など，役に立ちそうな特徴を利用し，かつ系列としての確からしさを評価しながら探索的に出力を求める手法として，識別モデルの一つである対数線型モデルを応用する方法を考えます．

対数線型モデルに基づくと，入力$\bm{x}$が与えられたときの出力$\bm{y}$の条件付き確率は，式(13.1)のように表現できます．

ここで$\phi(\bm{x}, \bm{y})$は素性ベクトルで，各次元は$\bm{x}, \bm{y}$から定められる様々な素性，$\bm{w}$はそれらの素性の重みからなる重みベクトル，$Z_{\bm{x},\bm{w}}$は$Z_{\bm{x},\bm{w}}=\sum_{\bm{y}} exp(\bm{w}\cdot\phi(\bm{x}, \bm{y}))$で定義される定数で，$\sum_{\bm{y}}P(\bm{y}|\bm{x})=1$を保証するためのものです．

そして，式(13.1)の条件付き確率を用いると，出力$\bm{y}^*$は式(13.2)の最大化問題を解くことによって求まります．

この段階では，素性関数としては前後の入力や出力を自由に組み合わせることができるので，系列としての情報を反映したものを設定することができ，上記の問題点1は解決したように見えます．しかし，式(13.2)ではすべての可能な$\bm{y}$についての値を計算する必要があるので，まだ問題点2が解決していません．"
1306,"そうすると，式(13.2)は式(13.3)のように書き換えることができます．

式(13.3)右辺の和の部分の最大値を求めるには，先頭$t=1$からスタートして，その時点での最大値を求めて足し込んでゆくという操作を$t$を増やしながら繰り返すことになります．このような手順を
ビタビアルゴリズム
とよびます．

このような制限を設け，対数線型モデルを系列識別問題に適用したものを
条件付き確率場（Conditional Random Field: CRF）とよびます．

CRFの学習は，対数線型モデルほど簡単ではありませんが，識別の際の手順と同様に，素性関数の値が1つ前の出力にしか影響されないという条件のもとで，重複する計算をまとめることができるという性質を利用します．"
1307,
1308,
1309,"次に，「入力の系列長に関わらず出力の系列長が1である問題」を扱います．

出力が一つになったので，ラベルの膨大な組合せを扱う前節の設定よりもやさしく感じるかもしれません．しかし，この問題の難しさは，学習の際に観測されない隠れ変数の値を用いなければならない，という点にあります．

まず，簡単な例題を考えてみましょう．

PCで文書作成を行っているユーザのキー入力・マウス操作をシンボルで表して，その系列で初心者と熟練者を識別する問題を考えます．入力はキー入力・マウス操作を抽象化したもので，10以上の連続通常キー入力k，エラーキー（DeleteキーやBack spaceキー）入力e，ファイル保存や文字修飾などのGUI操作をgとします．

ここで知見として，初心者はキー入力kとGUI入力gを頻繁に繰り返し，かつ時間が経過するにつれてエラーeが増える傾向にあるとします．また，熟練者は最初にキー入力を重点的に，後からGUI入力をまとめて行う，という傾向があるとします．

初心者Bさんの操作記録は以下のようなものでした．

\begin{quote}
\tt k e k g k e k g g k g k k e g e e k e e e g e
\end{quote}

一方，熟練者Sさんの操作記録は以下のようなものでした．

\begin{quote}
\tt k k e k g k k k e k g k g g g e g k g
\end{quote}

そして，問題として以下のような系列が観測されたとき，この人は初心者か，熟練者かを識別するという状況を考えます．

\begin{quote}
\tt k g e k g k k g e k g e k e e k e g e k
\end{quote}"
1310,"この与えられた系列を$\bm{x}$として，クラス$y$（ただし，$y= B (初心者) or S (熟練者)$）の事後確率$P(y|\bm{x})$を何らかのモデルを使って計算することを考えます．ここで式(13.4)のような$\bm{x}, y$の同時確率を考える生成モデルアプローチをとるのが
\textbf{HMM}(Hidden Marcov Model: 隠れマルコフモデル)の考え方です．

HMMは，式(13.4)の$P(\bm{x}|y)$の値を与える確率的非決定性オートマトンの一種です．
各状態であるシンボルをある確率で出力し，ある確率で他の状態(あるいは自分自身)に遷移します．"
1311,"形式的に定義すると，HMMは以下の要素と確率で定義されます．

\begin{itemize}
\item 状態の集合: $\{S_i\}~~(1 \ge i \ge n)$
\item 初期状態，最終状態の集合
\item 遷移確率: 状態$i$から状態$j$への遷移確率$a_{ij}$
\item 出力確率: 状態$i$で記号$o$を出力する確率$b_i(o)$
\end{itemize}

このようなHMMの構造を仮定すると，状態$\pi_1$から状態$\pi_2$に移るセグメントを隠れ変数
とみてEMアルゴリズムで，各状態の確率を推定します．

HMMは式(13.4)の$P(\bm{x}|y)$を計算するものです．別途推定した$P(y)$との
積を求めることで，事後確率$P(y|\bm{x})$を最大とする$y$を求めることができます．

HMMは，13.1節の冒頭に挙げた3番目の問題，すなわち，入力の系列長と出力の系列長に，
明確な対応関係がない問題にも適用できます．

最も単純なモデル化では，クラス毎に作成したすべてのHMMの初期状態と最終状態をそれぞれ
1つにまとめ，最終状態から初期状態へ戻る遷移を加えれば，任意の長さの出力系列を
表すことができます．"
1312,
1313,"この連結されたHMMを用いて，入力系列に対して最も確率が高くなる遷移系列を
ビタビアルゴリズムによって求めます．最も確率が高くなる遷移系列が定まるということは，
全ての隠れ変数の値が定まるということに等しくなりますので，入力の各部分系列に
対して，出力が定まるということになります．"
1401,"第14章と第15章は，教師あり学習と教師なし学習のどちらでもない学習手法について説明します
（図14.1）．

% figure 14.1

この「どちらでもない」ということが何を意味かを正確に定義するのは難しい問題です．
今まで扱ってきた問題を単純化すると，手元の全ての入力例に対して望ましい出力が付けられている状況で，入力から出力へ写像する関数を獲得するという設定か，あるいはとにかく大量のデータがある状況で，それらに内在する性質を発見するという設定のいずれかで，
この2つには当てはまらないけれどデータを活用したい，という状況は現実には様々な設定でありそうです．

まず，典型的な「どちらでもない」状況は，教師信号が一部の学習データにのみ与えられている状況です．
例えば，特定の製品について書かれたブログエントリやツイートなどのWeb文書に対して，肯定的／否定的の分類を行いたいという
問題設定を考えます．クローラープログラムを使えば，その製品名を含むWeb文書を多数入手することができます．
しかし，それらに識別対象のターゲット（肯定的／否定的）を付けるのは手間の掛かる作業なので，
現実的には集めた文書の一部にしかターゲットを与えることができません．すなわち，少量のターゲット付きデータと，
大量のターゲット無しデータがある状況で識別器を構成するという設定になります．このような状況を半教師あり学習
と呼び，本章でその手法を検討してゆきます．"
1402,"上で定義したように，本章で扱う半教師あり学習は教師あり／なしの混在型データに対する識別学習です．
基本的には教師ありデータで識別器を作成して，教師なしデータをできるだけ識別器の性能向上に役立てるという
方針で学習手順を考えます．このような目的で教師なしデータを用いる際には，教師なしデータの性質に
ある程度の制約があります．



まず，入力が数値のベクトルである場合を考えましょう．図14.2左の図のように，データが
クラスタを形成していると見なすことができ，同一クラスタ内に異なるクラスのターゲットが混在していない
ような状況では，教師ありデータの分布から教師なしデータのターゲットを比較的高い精度で推測でき，それらが
識別器の性能向上に役立ちそうです．

% figure 14.2

一方，図14.2右の図のように，明確なクラスタが確認されず，識別境界は存在しそうだけど，
どのデータに教師信号が付いているかで推定される識別境界の位置が大きく異なりそうなデータは，間違った
方に分類された教師なしデータがかえって識別器の性能を下げる振る舞いをするかもしれません．
確率的モデルの生成的手法のことばで表現すると，正解なしデータから得られる$p(\bm{x})$に関する
情報が，$P(y|\bm{x})$の推定に役立つことが，半教師あり学習が成立する条件です．"
1403,"このようなことを考慮すると，入力が数値のベクトルである場合，半教師あり学習が可能なデータは
以下の仮定を満たしていることが必要になります．

\begin{itemize}
\item 半教師あり平滑性仮定\\
　もし二つの入力 $\bm{x}_1$ と $\bm{x}_2$ が高密度領域
　
　で近ければ，出力 $y_1$ と $y_2$ も関連している
\item クラスタ仮定\\
　もし入力が同じクラスタに属するなら，それらは同じクラスになりやすい
\item 低密度分離\\
　識別境界は低密度領域にある
\item 多様体仮定\\
　高次元のデータは，低次元の多様体上に写像できる
\end{itemize}

最後の仮定は，多次元でも「次元の呪い」にかかっていない，ということです．
第7章で行った，多次元空間への写像の逆が成り立っているということになります．"
1404,"カテゴリ特徴の場合は，数値特徴の場合のような一般化は難しいのですが，カテゴリ特徴で
大量に学習データが入手可能な状況というのは，ほぼ言語データの識別問題に絞られます．

最も簡単なケースは図14.3のように，教師ありデータで抽出された
特徴語の多くが教師なしデータに含まれる場合です．このように識別に役立つ語の
オーバーラップが多いデータは教師なしデータに対しても比較的高い精度でターゲットを
付けることができ，口述する自己学習などを使えば，よい識別器ができそうです．"
1405,"しかし，通常はそう簡単にはゆきません．図14.3の例で示したような
商品の評価を行う文書にしても，褒める言葉やけなす言葉は様々なバリエーションがあります．
顔文字を使ったり，略語を使ったりもするでしょう．
そのような場合，正解付きデータと特徴語のオーバーラップが多い正解なしデータに
ラベル付けを行って正解ありデータに取り込んでしまった後，新たな頻出語を特徴語と
することによって，連鎖的に特徴語を増やしてゆくという手段が考えられます（図14.4）．

% figure 14.4

つまり，ラベル特徴の場合，教師ありデータと教師なしデータにラベル値のオーバーラップが全く見られないデータ
では，半教師あり学習は役に立ちませんが，教師なしデータの一部とでも適当なオーバーラップがあれば，その一部の
教師なしデータが他の教師なしデータを徐々に巻き込んでゆく可能性があります．通常，自然言語で書かれたデータは
この後者の仮定を満たすことが多いので，半教師あり学習は文書分類問題によく適用されます．"
1406,"ここまで見てきたように，特徴ベクトルが数値であってもラベルであっても，教師ありデータで作成した識別器の
パラメータを，教師なしデータを用いて調整してゆく，というのが半教師あり学習の基本的な進め方です（この章の
最後に紹介するYATSIアルゴリズムは例外です）．

識別器を作成するアルゴリズムはこれまで紹介してきたものを問題に応じて用いればよいのですが，
信用できる出力をする教師なしデータを次回の識別器作成に取り込むためには，ナイーブベイズ
識別器のような，その識別結果に確信度を伴うものが適切です．

一方，繰り返しアルゴリズムに関して，単純に終了のための閾値チェックをするだけなのか，
識別器のパラメータを繰り返しの度に変化させるか，識別器で使う特徴に制限をかけるか，など
様々な設定が可能です．以下では，繰り返しアルゴリズムの違いによって生じる，様々な
半教師あり学習手法について説明してゆきます．"
1407,"自己学習(self-training)は，最も単純な半教師あり学習アルゴリズムで，
教師ありデータで作成した識別器の出力のうち，確信度の高い結果を信じて，そのデータを教師ありデータに取り込んで，
自分を再度学習させるということを繰り返すものです(図14.5)

% figure 14.5

自分が出した結果を信じて，再度自分を学習させるというところが自己学習と呼ばれる理由です．
繰り返しによって学習データが増加し，より信頼性の高い識別器ができることをねらっています．"
1408,"自己学習は図14.2左の図のような，半教師あり学習に適したデータの場合はよいのですが，
低密度分離が満たされていないデータに対しては，教師ありデータによって作成した初期識別器の誤りが
ずっと影響を及ぼし続ける性質があります．"
1409,"自己学習の問題点は，自分が出した誤りを指摘してくれる他人がいない，というたとえができます．
そこで，判断基準が異なる識別器を2つ用意して，お互いが教え合うというたとえで半教師あり学習
を実現する方法が，共訓練(Co-training)です．

% figure 14.6

共訓練は，異なった特徴を用いて識別器を2つ作成し，相手の識別結果を利用して，それぞれの識別器を学習させる
アルゴリズムです．まず，教師付きデータの分割した特徴から識別器1と識別器2を作成し，教師なしデータをそれぞれで識別
します．識別器1の確信度上位$k$個を教師付きデータとみなして，識別器2を学習します，その後，1と2の役割を入れ替え，
精度の変化が少なくなるまで繰り返します．"
1410,"共訓練の特徴は，学習初期の誤りに強いということが挙げられます．欠点としては，それぞれが識別器と
して機能し得る異なる特徴集合を見つけるのが難しいことと，場合によっては全特徴を用いた自己学習の
方が性能がよいことがあること，などです．"
1411,"ラベル特徴の教師あり／なしの混合データに対する半教師あり学習のように，特徴的なラベルが同じクラスの
データで伝播するような性質がある場合は，自己学習や共訓練のような繰り返しアルゴリズムが効果を発揮します．
しかし，数値特徴では繰り返しアルゴリズムがうまく働く場合と，初期の誤りがその後の結果に影響を及ぼし続けて
あまりよい結果とならない場合があります．

そこで，繰り返しによる誤りの増幅を避けるために，教師ありデータで一度だけ識別器を学習し，その識別器で
全ての教師なしデータの識別してしまい，その結果を重み付きで利用してk-NN法による識別器を作る，という
単純なアルゴリズムがYATSI(Yet Another Two-Stage Idea)です（図14.7）．

% figure 14.7

教師ありデータを$D_l$，教師なしデータを$D_u$として，以下のアルゴリズムで重み付きk-NN識別器を
作成します．

% algorithm 14.1

ここで，$F$は教師なしデータの寄与分で，どれだけ教師なしデータの識別結果を信用するか，
というパラメータです．このようにして作成した重み付きk-NN識別器でテストデータを識別します．"
1412,"ラベル伝搬法の考え方は，
特徴空間上のデータをノードとみなし，類似度に基づいたグラフ構造を構築する
というものです．
近くのノードは同じクラスになりやすいという仮定で，正解なしデータの予測を行います．

評価関数は式(14.1)に示すもので，この評価関数の最小化をおこないます．

% equation 14.1

$f_i$は$i$番目のノードの予測値，$y_i$は$i$番目のノードの正解ラベル{ -1, 0, 1}，$w_{ij}$は$i$番目のノードと$j$番目のノードの結合の有無を表します．"
1413,"最小化の手順は，以下の通りです．

\begin{enumerate}
\item データ間の類似度に基づいて，データをノードとしたグラフを構築\\
類似度の基準は，RBF ($K(\bm{x}, \bm{x}') = \exp(-\gamma \| \bm{x} -\bm{x}' \|^2 )$)や，k-NNが使われます．前者は，全ノードが結合し，
連続値の類似度が与えられます．後者は，近傍のk個のノードのみが結合する省メモリの手法で，結合の有無は0または1で表現されます．"
1414,"\item ラベル付きノードからラベルなしノードにラベルを伝播させる操作を繰り返し，隣接するノードがなるべく同じラベルを持つように最適化
\end{enumerate}"
1501,この章では，強化学習について説明します．強化学習は，教師信号ではないがそれに準ずる情報が，一部の学習データにのみ与えられている状況での学習とみることができるので，中間的学習として位置付けています（図15.1）．
1502,"強化学習
とは，「報酬を得るために，環境に対して何らかの行為を行う意思決定エージェントの学習」と定義することができます（図15.2）．

実世界で行為を行う意思決定エージェントというと，ロボットが思いつきます．
バーチャルな世界で思いつきやすいのは，将棋や囲碁などを行うプログラムでしょうか．強化学習は，このような意思決定を行うエージェントを賢くする学習法です．

エージェントには，環境についての情報が与えられます．たとえば，ロボットでは，センサ・カメラ・マイクなどからの入力が環境となります．多種多様な環境を連続的に考えるのは難しいので，環境は離散的な状態の集合$S=\{s|s \in S\}$
でモデル化できると仮定します．時刻$t$で，ある状態$s_t$において，エージェントが行為$a_t$を行うと，報酬$r_{t+1}$が得られ，状態$s_{t+1}$に遷移します．
一般に，状態遷移は確率的で，その確率は遷移前の状態にのみ依存すると考えます．このような問題の定式化を
マルコフ決定過程(Markov Decision Process: MDP)
とよびます．

また，強化学習で考えている問題では，報酬$r$はたまにしか与えられません．
将棋やチェスなどのゲームを考えると，個々の手が良いか，悪いかはその手だけでは判断できず，
最終的に勝ったときに報酬が与えられます．ロボットが迷路を移動する問題でも，個々の道の
選択には報酬は与えられず，ゴールにだとりついた段階で報酬が与えられます．この場合，
回り道をすれことを避けるために，選択毎にマイナスの報酬を与える場合もあります．

このように定式化すると，強化学習は，なるべく多くの報酬を得ることを目的として，
状態(ラベル)または状態の確率分布（連続値）を入力として，行為（ラベル）
を出力する関数を学習することと定義できます．

ただし強化学習は，その設定上，これまでの教師あり／教師なし学習とは違う問題になります．
他の機械学習手法との違いは以下のようになります．

\begin{itemize}
\item 教師信号が間接的\\
　「何が正解か」ではなく，時々報酬の形で与えられる
\item 報酬が遅れて与えられる\\
　例)将棋の勝利，迷路のゴール
\item 探求が可能\\
　エージェントが自分で学習データの分布を変えられる
\item 状態が確定的でない場合がある\\
　確率分布でそれぞれの状態にいる確率を表す
\end{itemize}"
1503,"このような設定で，最も単純な例から始めましょう．対象とするものは
K-armed banditと呼ばれる，$K$本のアームを持つスロットマシンです（図15.3）
．

$K$本のアームのうち，どのアームを引くかによって賞金が変わるものとします．
これは，1状態，$K$種の行為，即時報酬の問題となります．学習結果は，この
スロットマシン（すなわちこの唯一の状態）で，最大の報酬を得る行為
（$K$本のうちどのアームを引くか）になります．

もし，報酬が決定的であれば，学習は非常に簡単です．
全ての行為を順に試みて最も報酬の高い行為を選べばよいのです．
あまりにも単純ですが，今後のことを考えて学習過程を定式化しておきましょう．

行為$a$の価値を$Q(a)$と定義し，学習過程によって正しい$Q(a)$の値(以後Q値といいます)が得られれば，
Q値を最大とする行為が学習の結果になります．
最初は，行為$a$を行ってどれだけの報酬が得られるのかわからないので，全ての$a$について$Q(a)$の値を0に
初期化します．次に，可能な$a$を順番に行って($K$本のアームを順番に引いて)，
そのときの報酬$r_a$を得ます．そして，各$a$について$Q(a)= r_a$として，
Q値がいちばん高い$a$が求める行為になります．


一方，報酬が非決定的な場合は，こんなに簡単にはゆきません．各行為$a$に対応する報酬
$r$は，非決定的ですがまったくでたらめではなく，確率分布$p(r|a)$に従うと仮定します
．
つまり，決定的ではないが，確率的であると仮定します．ただし，この確率分布は未知だとします．

そのような状況では，各アームを1回だけ引くのではなく，何度も引いて，平均的に多くの報酬が得られるアーム
を選ぶことになります．何回も試行することで，確率分布$p(r|a)$を推定するわけです．

何度も試行して学習を行うので，定式化に時刻$t$を持ち込みます．扱いやすいように，$t$は離散的であるとして，
時刻$t$で一回試行，時刻$t+1$で次の試行と続けてゆくと考えます．この場合，行為$a$の価値の時刻$t$における
見積りを$Q_t(a)$とします．このQ値を時刻$t$以前での，行為$a$による報酬の平均値に一致させることを目指します．
そうすると，その行為が平均的にどれぐらいうまくゆくか，ということがわかります．

ただし，単純に平均値を求めるためには，それまでの行為$a$の試行回数を記憶しておかなければなりませんし，
Q値はずっと変動し続けます．そこで，式(15.1)のように，時刻$t$の行為$a$による試行の
報酬$r_{t+1}$と，現在の
Q値との差を変動幅とし，学習係数$\eta$をかけてQ値の更新を行います．学習率$\eta$は最初は1以下の適当な値に
設定し，時刻$t$の増加に従って減少するようにしておけば，試行を重ねてゆけばQ値が収束します．"
1504,
1505,"次に，複数の状態を持つ問題に拡張しましょう．図15.4のような迷路をロボットRが
移動するという状況です．ゴールGに着けば，報酬が得られます．

単純なケースでは報酬は決定的（ゴールに着けば必ずもらえる）で，部屋の移動にあたる状態遷移も
決定的（必ず意図した部屋に移動できる）です．問題を一般化して，報酬や遷移が確率的である場合も
想定できます．これらが確率的になる原因として，例えばロボットのゴールを探知するセンサーが
ノイズで誤動作をしたり，路面状況でスリップが生じるなどの不確定な要因で行為が成功しない状況が
考えられます．これらは，非決定的であるとはいえ，学習中に状況が変化してしまうとどうしようもないので，
この非決定性が確率的であるとし，確率分布は学習期間中を通じて一定であるとします．

このような問題は，以下のようなマルコフ決定過程として定式化
することができます．

\begin{itemize}
\item 時刻$t$における状態$s_t \in S$
\item 時刻$t$における行為$a_t \in A(s_t)$
\item 報酬 $r_{t+1} \in R$，確率分布$p(r_{t+1}|s_t, a_t)$
\item 次状態$s_{t+1} \in S$，確率分布$P(s_{t+1}|s_t, a_t)$
\end{itemize}

マルコフ決定過程は，「マルコフ性」を持つ確率過程における意思決定問題で，「マルコフ性」とは
次状態での事象の起こる確率は現在の状態だけから決まり，過去の状態には依存しないという性質です．
ここでは，報酬と次状態への遷移の確率が現在の状態と行為のみに依存しているという定式化に
なっています．"
1506,"マルコフ決定過程における学習は，各状態でどの行為を取ればよいのかという意思決定規則を
獲得してゆくプロセスです．意思決定規則のことを政策$\pi$と呼び，状態から行為への関数の形で表現
します．

政策の良さは，その政策に従って行動したときの累積報酬の期待値で評価します．
状態$s_t$から政策$\pi$に従って行動したときに得られる累積報酬の期待値は式(15.2)のように計算できます．
ただし，$\gamma (0 \le \gamma < 1)$は割引率で，後に得られる報酬ほど割り引いて計算するための係数です．この係数を
累積計算に組み込むことで，同じ報酬にたどり着けるのであればより短い手順を優先することになり，ずっと先の報酬を
小さくすることで累積計算を収束させることにもなります．

累積報酬の期待値を全ての状態に対して最大となる政策を最適政策$\pi^*$といいます．
マルコフ決定過程における学習の目標は，この最適政策$\pi^*$を獲得することです．"
1507,"最適政策$\pi^*$に従ったときの累積報酬の期待値$V^{\pi^*} (s_t)$は，見やすさのため，以後$V^* (s_t)$と
表記します．

この最適政策を求めるための考え方は，K-armed bandit問題と同じで，各状態において
$Q(s_t, a_t)$（状態$s_t$ で行為$a_t$ を行うときの価値）の値を，問題の状況設定に従って
求めてゆく，というものです．

$Q^*(s_t, a_t)$を状態$s_t$ で行為$a_t$ を行い，その後最適政策に従ったときの期待累積報酬の
見積もりとすると，$V^*$と$Q^*$の関係から，以下の式が導けます．"
1508,"式(15.4)は，無限時刻の和で表現される状態価値関数を，隣接時刻間の再帰方程式で表したものです．
この再帰方程式を
ベルマン方程式 
(Bellman equation)といいます．状態遷移確率を明示的にすると，
ベルマン方程式は以下のように書き換えられます．

さらに，式(15.5)を，Q値を用いて書き換えると，以下のようになります．

求めるべき最適政策は，Q値を用いて，以下のように表現できます．

後は，どのようにしてQ値を推定するか，という問題になります．"
1509,"Q値を推定する方法は，モデルの関する知識の前提によって大きく2つに分類されます．
環境をモデル化する知識，すなわち，状態遷移確率と報酬の確率分布が与えられている場合，
Q値は，動的計画法の考え方を用いて求めることができます．この方法を
モデルベースの手法 と
呼びます．一方，環境のモデルを持っていない場合，すなわち，状態遷移確率と報酬の確率分布が
未知の場合，試行錯誤を通じて環境と相互作用をした結果を使って学習を行います．この方法を
モデルフリーの手法 と呼びます．

本節ではモデルベースの手法を，次節ではモデルフリーの手法を説明します．

モデルベースの手法では，状態遷移確率$P(s_{t+1}|s_t, a_t)$と，報酬の確率分布$p(r_{t+1}|s_t, a_t)$が
与えられているものとします．その前提で，アルゴリズム15.1に示すValue iterationアルゴリズムを実行すると，
状態価値関数$V(s)$の最適値を求めることができ，それぞれの状態でQ値を最大とする行為が求まりますので，
これが最適政策ということになります．

アルゴリズム15.1 中の報酬の期待値$E(r|s,a)$は報酬の確率分布$p(r_{t+1}|s_t, a_t)$から求めます．
このアルゴリズムは，迷路中で報酬がもらえる状態（ゴール）が1つだけある場合，まずそのゴール
状態の1つ手前での最適行為が得られ，次にその1つ手前，さらにその1つ手前と，繰り返しを回る毎に
正しい最適値が得られている状態がゴールを中心に広がってゆくイメージをしていただけると，
わかりやすいと思います．

また，モデルベースの手法には，Value iterationアルゴリズムの他にも，
適当な政策を初期値として，そのもとでの状態価値関数$V(s)$を計算し，各状態で現在の
知識から得られる最適行為を選び直すことを繰り返すPolicy iterationアルゴリズムもあります．"
1510,"環境モデルが未知の場合，TD(Temporal Difference)学習と呼ばれる方法を使います．

環境の探索が必要なので，探索戦略としてε-greedy法を使います．
ε-greedy法は確率$1-\epsilon$で最適な行為，確率$\epsilon$でそれ以外の行為を実行する探索手法の総称で，
実際にはQ値を確率に変換したものを基準に行為を選択します．

ただし，探索の初期はいろいろな行為を試し，落ち着いてくると最適な行為を多く選ぶように
するように，温度の概念を導入します．温度を$T$として，式(15.8)で表される確率に従って
行為を選びます．

$T$を
アニーリング(焼き鈍し)
における温度と呼び，高ければすべての行為を等確率に近い確率で選択し，
低ければ最適なものに偏ります．学習が進むにつれて，$T$の値を小さくすることで，学習結果が安定します．"
1511,"まず，報酬と遷移は，未知ではあるが決定的に定まる，という状況でのTD学習を考えます．
このような状況の例としては図15.5のような迷路での最適行為の獲得を考えます．

この場合のベルマン方程式は式(15.9)のようになります．"
1512,このベルマン方程式を用いて，以下のアルゴリズムでQ値が求まります．
1513,"次に報酬と遷移が非決定的なTD学習を考えます．

この場合，報酬$r$が確率的であるので，決定性のアルゴリズムでは値が変化し続けることになります．
そこで，1状態・非決定性の問題で検討したように，Q値の更新を現在のQ値に一定割合の更新分の加え，
その一定割合を時間とともに減らしてゆく，という更新式を用います．式は以下のようになります．

式(15.10)の学習係数$\eta$を適切に設定すると，各状態ですべての行為を十分な回数行える
という前提で，Q値が収束することが証明されています．しかし，これはあくまで理論上で，
実際にロボットを動かして強化学習を行わせるようなケースは少なく，パラメータを変えて
シミュレーション結果を評価する事例が多く見られます．"
1514,"MDP設定下での強化学習では，エージェントは行為後の次状態を環境から受け取るという仮定を置いています．
つまり，エージェントは今，どの状態にいるのか，確定した情報を持っているということです．

しかし，現実世界でロボットを動かした場合，ロボットの入力はカメラやセンサから得る値ですので，
これらの情報から確実に状態を特定できるとは限りません．エージェントは観測された情報(部分的な状態の情報)
を受け取る，という設定の方が現実的です．つまり，エージェントは現在の状態が確定できない
状況で，意思決定を行うということになります（図15.7）．

このような状況は，部分観測マルコフ決定過程(POMDP; Partially Observable MDP)による定式化が適しています．

部分観測マルコフ決定過程の要素は以下のものです．

\begin{itemize}
\item 状態$s_t$で行為$a_t$を行うと観測$o_{t+1}$が確率的に得られる
\item エージェントは状態の確率分布を信念状態$b_t$として持つ
\item エージェントは，信念状態$b_t$，行為$a_t$，観測$o_{t+1}$から次の信念状態$b_{t+1}$を推定する
状態見積器(state estimator)を内部に持つ
\end{itemize}"
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
